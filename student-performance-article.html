<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>پیش‌بینی عملکرد تحصیلی دانش‌آموزان با استفاده از تکنیک‌های داده‌کاوی</title>
    <style>
        body {
            font-family: 'B Nazanin', 'B Yekan', Tahoma, Arial;
            line-height: 2;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background-color: white;
            padding: 40px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            font-size: 28px;
            margin-bottom: 10px;
            padding-bottom: 15px;
            border-bottom: 3px solid #3498db;
        }
        h2 {
            color: #34495e;
            font-size: 22px;
            margin-top: 30px;
            margin-bottom: 15px;
            padding-right: 10px;
            border-right: 4px solid #3498db;
        }
        h3 {
            color: #555;
            font-size: 18px;
            margin-top: 20px;
            margin-bottom: 10px;
        }
        p {
            text-align: justify;
            margin-bottom: 15px;
            color: #333;
        }
        .abstract {
            background-color: #ecf0f1;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-right: 5px solid #3498db;
        }
        .keywords {
            font-weight: bold;
            color: #2c3e50;
            margin-top: 10px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: center;
        }
        th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f2f2f2;
        }
        .figure {
            text-align: center;
            margin: 20px 0;
            padding: 15px;
            background-color: #f8f9fa;
            border-radius: 5px;
        }
        .figure-caption {
            font-size: 14px;
            color: #666;
            margin-top: 10px;
            font-style: italic;
        }
        ul, ol {
            margin-right: 20px;
            margin-bottom: 15px;
        }
        li {
            margin-bottom: 8px;
        }
        .author-info {
            text-align: center;
            margin: 20px 0;
            color: #555;
            font-size: 16px;
        }
        .results-box {
            background-color: #e8f5e9;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            border-right: 4px solid #4caf50;
        }
        .warning-box {
            background-color: #fff3e0;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            border-right: 4px solid #ff9800;
        }
        .highlight {
            background-color: #ffeb3b;
            padding: 2px 5px;
            border-radius: 3px;
        }
        .equation {
            text-align: center;
            margin: 20px 0;
            font-style: italic;
            color: #555;
        }
        .references {
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #ddd;
        }
        .reference-item {
            margin-bottom: 10px;
            padding-right: 20px;
            text-indent: -20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- عنوان مقاله -->
        <h1>پیش‌بینی عملکرد تحصیلی دانش‌آموزان با استفاده از تکنیک‌های ترکیبی داده‌کاوی: رویکردی جامع با Classification، Clustering و Association Rules</h1>
        
        <div class="author-info">
            پروژه داده‌کاوی - سالار لطفی , نازنین خاکسبز<br>
            تاریخ: شهریور ۱۴۰۴
        </div>

        <!-- چکیده -->
        <div class="abstract">
            <h2>چکیده</h2>
            <p>
                پیش‌بینی عملکرد تحصیلی دانش‌آموزان یکی از چالش‌های مهم در حوزه آموزش است که می‌تواند به شناسایی زودهنگام دانش‌آموزان در معرض خطر افت تحصیلی کمک کند. این پژوهش با هدف توسعه یک سیستم جامع پیش‌بینی عملکرد تحصیلی، از ترکیب سه رویکرد اصلی داده‌کاوی شامل طبقه‌بندی (Classification)، خوشه‌بندی (Clustering) و قوانین همبستگی (Association Rules) استفاده می‌کند. داده‌های مورد استفاده شامل ۱۰۰۰ رکورد از دانش‌آموزان با ۱۷ ویژگی مختلف است. در فاز طبقه‌بندی، ۹ الگوریتم مختلف پیاده‌سازی شد که مدل شبکه عصبی با F1-Score برابر ۰.۵۲ بهترین عملکرد را داشت. در فاز خوشه‌بندی، الگوریتم GMM با Silhouette Score برابر ۰.۴۱۶۱ بهترین نتیجه را ارائه داد. همچنین ۱۳,۸۸۵ قانون همبستگی استخراج شد که ۴۳۱ قانون قوی با Confidence بالای ۰.۷ شناسایی شدند. نتایج نشان می‌دهد که عوامل کلیدی موثر بر عملکرد تحصیلی شامل نرخ حضور، ساعات مطالعه، عملکرد قبلی و حمایت والدین هستند.
            </p>
            <div class="keywords">
                <strong>کلمات کلیدی:</strong> داده‌کاوی آموزشی، پیش‌بینی عملکرد دانش‌آموزان، طبقه‌بندی، خوشه‌بندی، قوانین همبستگی، یادگیری ماشین
            </div>
        </div>

        <!-- مقدمه -->
        <h2>۱. مقدمه</h2>
        
        <h3>۱.۱ بیان مسئله</h3>
        <p>
            سیستم‌های آموزشی در سراسر جهان با چالش شناسایی و پشتیبانی از دانش‌آموزانی که در معرض خطر افت تحصیلی قرار دارند، مواجه هستند. پیش‌بینی زودهنگام عملکرد تحصیلی می‌تواند به مربیان و مدیران آموزشی کمک کند تا مداخلات هدفمند و به‌موقع را طراحی و اجرا کنند. با توجه به حجم عظیم داده‌های آموزشی موجود، استفاده از تکنیک‌های داده‌کاوی می‌تواند الگوهای پنهان و عوامل موثر بر موفقیت یا شکست تحصیلی را آشکار سازد.
        </p>

        <h3>۱.۲ اهمیت موضوع</h3>
        <p>
            اهمیت این پژوهش از چند منظر قابل بررسی است. از نظر علمی، این مطالعه رویکردی ترکیبی و جامع برای تحلیل داده‌های آموزشی ارائه می‌دهد که می‌تواند به توسعه دانش در حوزه Educational Data Mining کمک کند. از منظر عملی، نتایج این پژوهش می‌تواند به بهبود کیفیت آموزش، کاهش نرخ افت تحصیلی، و بهینه‌سازی تخصیص منابع آموزشی منجر شود. همچنین، شناسایی عوامل کلیدی موثر بر عملکرد تحصیلی می‌تواند در طراحی برنامه‌های آموزشی شخصی‌سازی شده مورد استفاده قرار گیرد.
        </p>

        <h3>۱.۳ اهداف و سوالات تحقیق</h3>
        <p>هدف اصلی این پژوهش، توسعه یک سیستم جامع و دقیق برای پیش‌بینی عملکرد تحصیلی دانش‌آموزان با استفاده از تکنیک‌های مختلف داده‌کاوی است. سوالات اصلی تحقیق عبارتند از:</p>
        <ul>
            <li>کدام الگوریتم طبقه‌بندی بهترین عملکرد را در پیش‌بینی وضعیت قبولی/رد دانش‌آموزان دارد؟</li>
            <li>آیا می‌توان دانش‌آموزان را بر اساس ویژگی‌های تحصیلی و رفتاری در گروه‌های همگن دسته‌بندی کرد؟</li>
            <li>چه قوانین همبستگی قوی بین ویژگی‌های مختلف و عملکرد تحصیلی وجود دارد؟</li>
            <li>کدام عوامل بیشترین تاثیر را بر موفقیت یا شکست تحصیلی دانش‌آموزان دارند؟</li>
        </ul>

        <h3>۱.۴ ساختار گزارش</h3>
        <p>
            این گزارش در ۱۱ بخش سازماندهی شده است. پس از مقدمه، بخش ۲ به مرور ادبیات موضوع می‌پردازد. بخش ۳ داده‌ها و ویژگی‌های آنها را توصیف می‌کند. بخش ۴ روش‌ها و الگوریتم‌های استفاده شده را تشریح می‌کند. بخش‌های ۵ تا ۷ به ترتیب نتایج، تحلیل و بحث را ارائه می‌دهند. بخش ۸ اعتبارسنجی آماری نتایج را بررسی می‌کند و در نهایت، بخش ۹ نتیجه‌گیری و پیشنهادات را ارائه می‌دهد.
        </p>

        <!-- مرور ادبیات -->
        <h2>۲. مرور ادبیات</h2>
        
        <h3>۲.۱ مطالعات پیشین</h3>
        <p>
            در سال‌های اخیر، مطالعات متعددی در زمینه پیش‌بینی عملکرد تحصیلی با استفاده از تکنیک‌های داده‌کاوی انجام شده است. Romero و Ventura (2020) در مطالعه جامع خود، بیش از ۳۰۰ مقاله در حوزه Educational Data Mining را مرور کردند و نشان دادند که الگوریتم‌های طبقه‌بندی، به‌ویژه Decision Trees و Neural Networks، پرکاربردترین روش‌ها در این حوزه هستند. Kumar و Pal (2021) با استفاده از الگوریتم Naive Bayes توانستند با دقت ۷۸٪ عملکرد دانشجویان را پیش‌بینی کنند. 
        </p>

        <h3>۲.۲ مفاهیم اصلی</h3>
        
        <h4>۲.۲.۱ الگوریتم‌های طبقه‌بندی</h4>
        <p>
            طبقه‌بندی یکی از تکنیک‌های اصلی یادگیری با نظارت است که هدف آن پیش‌بینی برچسب کلاس برای نمونه‌های جدید بر اساس الگوهای آموخته شده از داده‌های آموزشی است. در این پژوهش، از الگوریتم‌های مختلفی شامل:
        </p>
        <ul>
            <li><strong>شبکه‌های عصبی مصنوعی (Neural Networks):</strong> مدل‌هایی الهام‌گرفته از مغز انسان که قابلیت یادگیری الگوهای پیچیده غیرخطی را دارند</li>
            <li><strong>ماشین بردار پشتیبان (SVM):</strong> الگوریتمی که با یافتن ابرصفحه بهینه، داده‌ها را در فضای چندبعدی جدا می‌کند</li>
            <li><strong>جنگل تصادفی (Random Forest):</strong> روش ensemble که از ترکیب چندین درخت تصمیم برای بهبود دقت استفاده می‌کند</li>
            <li><strong>رگرسیون لجستیک:</strong> مدل آماری برای پیش‌بینی احتمال وقوع یک رویداد دودویی</li>
        </ul>

        <h4>۲.۲.۲ الگوریتم‌های خوشه‌بندی</h4>
        <p>
            خوشه‌بندی یک تکنیک یادگیری بدون نظارت است که هدف آن گروه‌بندی داده‌ها بر اساس شباهت‌های ذاتی است. الگوریتم‌های استفاده شده شامل:
        </p>
        <ul>
            <li><strong>K-Means:</strong> الگوریتمی که داده‌ها را به K خوشه تقسیم می‌کند با هدف حداقل‌سازی واریانس درون‌خوشه‌ای</li>
            <li><strong>DBSCAN:</strong> روشی مبتنی بر چگالی که قابلیت شناسایی خوشه‌های با شکل دلخواه را دارد</li>
            <li><strong>GMM (Gaussian Mixture Model):</strong> مدل احتمالاتی که فرض می‌کند داده‌ها از ترکیب چند توزیع گاوسی تولید شده‌اند</li>
            <li><strong>Hierarchical Clustering:</strong> روشی که ساختار سلسله‌مراتبی خوشه‌ها را ایجاد می‌کند</li>
        </ul>

        <h4>۲.۲.۳ قوانین همبستگی</h4>
        <p>
            کشف قوانین همبستگی به دنبال یافتن روابط جالب بین متغیرها در پایگاه‌های داده بزرگ است. دو الگوریتم اصلی استفاده شده عبارتند از:
        </p>
        <ul>
            <li><strong>Apriori:</strong> الگوریتم کلاسیک که با استفاده از رویکرد bottom-up، مجموعه‌های پرتکرار را شناسایی می‌کند</li>
            <li><strong>FP-Growth:</strong> الگوریتم بهینه‌تر که با ساخت درخت FP، نیاز به اسکن‌های متعدد پایگاه داده را کاهش می‌دهد</li>
        </ul>

        <!-- داده‌ها و ویژگی‌ها -->
        <h2>۳. داده‌ها و ویژگی‌های آنها</h2>
        
        <h3>۳.۱ منبع و توصیف داده‌ها</h3>
        <p>
            مجموعه داده مورد استفاده در این پژوهش شامل اطلاعات ۱۰۰۰ دانش‌آموز با ۱۷ ویژگی مختلف است. این داده‌ها از فایل CSV با نام "student_performance_updated_1000.csv" بارگذاری شده‌اند. داده‌ها شامل ترکیبی از ویژگی‌های عددی و دسته‌ای هستند که جنبه‌های مختلف عملکرد تحصیلی و ویژگی‌های دموگرافیک دانش‌آموزان را پوشش می‌دهند.
        </p>

        <h3>۳.۲ ویژگی‌های داده‌ها</h3>
        <table>
            <thead>
                <tr>
                    <th>نام ویژگی</th>
                    <th>نوع</th>
                    <th>توضیحات</th>
                    <th>محدوده/مقادیر</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>StudentID</td>
                    <td>عددی</td>
                    <td>شناسه یکتای دانش‌آموز</td>
                    <td>1-1000</td>
                </tr>
                <tr>
                    <td>Gender</td>
                    <td>دسته‌ای</td>
                    <td>جنسیت دانش‌آموز</td>
                    <td>Male/Female</td>
                </tr>
                <tr>
                    <td>AttendanceRate</td>
                    <td>عددی</td>
                    <td>نرخ حضور در کلاس</td>
                    <td>0-100%</td>
                </tr>
                <tr>
                    <td>StudyHoursPerWeek</td>
                    <td>عددی</td>
                    <td>ساعات مطالعه هفتگی</td>
                    <td>0-40 ساعت</td>
                </tr>
                <tr>
                    <td>PreviousGrade</td>
                    <td>عددی</td>
                    <td>نمره دوره قبلی</td>
                    <td>0-100</td>
                </tr>
                <tr>
                    <td>ExtracurricularActivities</td>
                    <td>عددی</td>
                    <td>میزان فعالیت‌های فوق‌برنامه</td>
                    <td>0-10</td>
                </tr>
                <tr>
                    <td>ParentalSupport</td>
                    <td>دسته‌ای</td>
                    <td>سطح حمایت والدین</td>
                    <td>Low/Medium/High</td>
                </tr>
                <tr>
                    <td>FinalGrade</td>
                    <td>عددی</td>
                    <td>نمره نهایی</td>
                    <td>0-100</td>
                </tr>
                <tr>
                    <td>Pass_Status</td>
                    <td>دسته‌ای (هدف)</td>
                    <td>وضعیت قبولی/رد</td>
                    <td>Pass/Fail</td>
                </tr>
            </tbody>
        </table>

        <h3>۳.۳ پیش‌پردازش داده‌ها</h3>
        <p>
            فرآیند پیش‌پردازش داده‌ها شامل مراحل زیر بود:
        </p>
        <ol>
            <li><strong>پردازش مقادیر گمشده:</strong> مقادیر گمشده در ویژگی‌های عددی با میانگین و در ویژگی‌های دسته‌ای با مد (پرتکرارترین مقدار) جایگزین شدند</li>
            <li><strong>ایجاد متغیر هدف:</strong> بر اساس میانه نمرات نهایی، دانش‌آموزان به دو گروه قبول و رد تقسیم شدند</li>
            <li><strong>کدگذاری متغیرهای دسته‌ای:</strong> با استفاده از LabelEncoder، متغیرهای دسته‌ای به مقادیر عددی تبدیل شدند</li>
            <li><strong>نرمال‌سازی:</strong> ویژگی‌های عددی با استفاده از StandardScaler نرمال‌سازی شدند تا میانگین صفر و انحراف معیار یک داشته باشند</li>
            <li><strong>تقسیم داده‌ها:</strong> داده‌ها با نسبت 80-20 به مجموعه‌های آموزشی (800 نمونه) و تست (200 نمونه) تقسیم شدند</li>
        </ol>

        <div class="results-box">
            <strong>نتیجه پیش‌پردازش:</strong> پس از اتمام پیش‌پردازش، تمامی مقادیر گمشده پردازش شدند و توزیع متوازنی از کلاس‌های قبول (50.1%) و رد (49.9%) حاصل شد.
        </div>

        <!-- روش‌ها و الگوریتم‌ها -->
        <h2>۴. روش‌ها و الگوریتم‌ها</h2>

        <h3>۴.۱ فاز طبقه‌بندی (Classification)</h3>
        <p>
            در این فاز، ۹ الگوریتم مختلف طبقه‌بندی پیاده‌سازی و مقایسه شدند:
        </p>

        <h4>۴.۱.۱ شبکه عصبی مصنوعی (MLP Classifier)</h4>
        <p>
            شبکه عصبی پیاده‌سازی شده از نوع Multilayer Perceptron با پارامترهای زیر بود:
        </p>
        <ul>
            <li>تعداد لایه‌های پنهان: 2 لایه با 100 نورون</li>
            <li>تابع فعال‌سازی: ReLU</li>
            <li>الگوریتم بهینه‌سازی: Adam</li>
            <li>نرخ یادگیری: 0.001</li>
            <li>حداکثر تکرار: 1000</li>
        </ul>

        <h4>۴.۱.۲ ماشین بردار پشتیبان (SVM)</h4>
        <p>
            دو نوع SVM پیاده‌سازی شد:
        </p>
        <ul>
            <li><strong>SVM خطی:</strong> با kernel='linear' برای جداسازی خطی داده‌ها</li>
            <li><strong>SVM با کرنل RBF:</strong> برای مدل‌سازی روابط غیرخطی پیچیده</li>
        </ul>

        <h4>۴.۱.۳ روش‌های Ensemble</h4>
        <ul>
            <li><strong>Random Forest:</strong> با 100 درخت تصمیم و عمق نامحدود</li>
            <li><strong>Gradient Boosting:</strong> با 100 estimator و نرخ یادگیری 0.1</li>
        </ul>

        <h3>۴.۲ فاز خوشه‌بندی (Clustering)</h3>
        
        <h4>۴.۲.۱ تعیین تعداد بهینه خوشه‌ها</h4>
        <p>
            برای تعیین تعداد بهینه خوشه‌ها از دو روش استفاده شد:
        </p>
        <ol>
            <li><strong>روش Elbow:</strong> با بررسی WCSS (Within-Cluster Sum of Squares) برای K از 2 تا 10</li>
            <li><strong>Silhouette Score:</strong> برای ارزیابی کیفیت خوشه‌بندی</li>
        </ol>

        <div class="figure">
            <p><strong>شکل 1:</strong> نمودار Elbow و Silhouette Score</p>
            <p class="figure-caption">بر اساس تحلیل‌ها، تعداد بهینه خوشه‌ها برابر با 2 تعیین شد</p>
        </div>

        <h4>۴.۲.۲ الگوریتم‌های خوشه‌بندی</h4>
        <table>
            <thead>
                <tr>
                    <th>الگوریتم</th>
                    <th>پارامترهای کلیدی</th>
                    <th>ویژگی‌های خاص</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>K-Means</td>
                    <td>K=2, n_init=10</td>
                    <td>سرعت بالا، خوشه‌های کروی</td>
                </tr>
                <tr>
                    <td>DBSCAN</td>
                    <td>eps=1.9, min_samples=5</td>
                    <td>شناسایی نقاط نویز، خوشه‌های با شکل دلخواه</td>
                </tr>
                <tr>
                    <td>GMM</td>
                    <td>n_components=2</td>
                    <td>مدل احتمالاتی، انعطاف‌پذیری بالا</td>
                </tr>
                <tr>
                    <td>Hierarchical</td>
                    <td>linkage='ward'</td>
                    <td>ساختار سلسله‌مراتبی، dendrogram</td>
                </tr>
            </tbody>
        </table>

        <h3>۴.۳ فاز قوانین همبستگی (Association Rules)</h3>
        
        <h4>۴.۳.۱ آماده‌سازی داده‌ها</h4>
        <p>
            برای استخراج قوانین همبستگی، ابتدا ویژگی‌های پیوسته به دسته‌ای تبدیل شدند:
        </p>
        <ul>
            <li><strong>AttendanceRate:</strong> به سه دسته Low، Medium و High تقسیم شد</li>
            <li><strong>StudyHoursPerWeek:</strong> به سه سطح Low_Study، Medium_Study و High_Study</li>
            <li><strong>PreviousGrade:</strong> به Poor، Average و Good تبدیل شد</li>
            <li><strong>ExtracurricularActivities:</strong> به Low، Medium و High Activities</li>
        </ul>

        <h4>۴.۳.۲ پارامترهای الگوریتم‌ها</h4>
        <ul>
            <li><strong>حداقل Support:</strong> 0.01 (حداقل 1% از تراکنش‌ها)</li>
            <li><strong>حداقل Confidence:</strong> 0.5 (50% اطمینان)</li>
            <li><strong>حداکثر طول قانون:</strong> 5 آیتم</li>
        </ul>

        <h3>۴.۴ معیارهای ارزیابی</h3>
        
        <h4>۴.۴.۱ معیارهای طبقه‌بندی</h4>
        <ul>
            <li><strong>Accuracy:</strong> نسبت پیش‌بینی‌های صحیح به کل پیش‌بینی‌ها</li>
            <li><strong>Precision:</strong> نسبت پیش‌بینی‌های مثبت صحیح به کل پیش‌بینی‌های مثبت</li>
            <li><strong>Recall:</strong> نسبت پیش‌بینی‌های مثبت صحیح به کل موارد واقعاً مثبت</li>
            <li><strong>F1-Score:</strong> میانگین هارمونیک Precision و Recall</li>
            <li><strong>AUC-ROC:</strong> سطح زیر منحنی ROC</li>
        </ul>

        <div class="equation">
            F1-Score = 2 × (Precision × Recall) / (Precision + Recall)
        </div>

        <h4>۴.۴.۲ معیارهای خوشه‌بندی</h4>
        <ul>
            <li><strong>Silhouette Score:</strong> معیاری بین -1 تا 1 که کیفیت خوشه‌بندی را نشان می‌دهد</li>
            <li><strong>Davies-Bouldin Index:</strong> نسبت شباهت درون‌خوشه‌ای به بین‌خوشه‌ای (کمتر بهتر)</li>
            <li><strong>Calinski-Harabasz Score:</strong> نسبت پراکندگی بین‌خوشه‌ای به درون‌خوشه‌ای (بیشتر بهتر)</li>
        </ul>

        <h4>۴.۴.۳ معیارهای قوانین همبستگی</h4>
        <ul>
            <li><strong>Support:</strong> فراوانی نسبی آیتم‌ست در کل تراکنش‌ها</li>
            <li><strong>Confidence:</strong> احتمال وقوع consequent به شرط وقوع antecedent</li>
            <li><strong>Lift:</strong> نسبت Confidence واقعی به Confidence مورد انتظار در حالت استقلال</li>
        </ul>

        <!-- نتایج -->
        <h2>۵. نتایج</h2>

        <h3>۵.۱ نتایج طبقه‌بندی</h3>
        
        <table>
            <thead>
                <tr>
                    <th>مدل</th>
                    <th>Accuracy</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1-Score</th>
                    <th>AUC</th>
                    <th>CV Mean ± Std</th>
                </tr>
            </thead>
            <tbody>
                <tr style="background-color: #d4edda;">
                    <td><strong>Neural Network</strong></td>
                    <td><strong>0.520</strong></td>
                    <td><strong>0.520</strong></td>
                    <td><strong>0.520</strong></td>
                    <td><strong>0.520</strong></td>
                    <td><strong>0.519</strong></td>
                    <td><strong>0.513 ± 0.017</strong></td>
                </tr>
                <tr>
                    <td>SVM (RBF)</td>
                    <td>0.520</td>
                    <td>0.520</td>
                    <td>0.520</td>
                    <td>0.520</td>
                    <td>0.545</td>
                    <td>0.516 ± 0.047</td>
                </tr>
                <tr>
                    <td>Random Forest</td>
                    <td>0.510</td>
                    <td>0.510</td>
                    <td>0.510</td>
                    <td>0.510</td>
                    <td>0.488</td>
                    <td>0.533 ± 0.015</td>
                </tr>
                <tr>
                    <td>Logistic Regression</td>
                    <td>0.490</td>
                    <td>0.490</td>
                    <td>0.490</td>
                    <td>0.489</td>
                    <td>0.508</td>
                    <td>0.509 ± 0.042</td>
                </tr>
                <tr>
                    <td>Gradient Boosting</td>
                    <td>0.480</td>
                    <td>0.480</td>
                    <td>0.480</td>
                    <td>0.479</td>
                    <td>0.478</td>
                    <td>0.526 ± 0.009</td>
                </tr>
                <tr>
                    <td>SVM (Linear)</td>
                    <td>0.465</td>
                    <td>0.465</td>
                    <td>0.465</td>
                    <td>0.464</td>
                    <td>0.474</td>
                    <td>0.519 ± 0.027</td>
                </tr>
                <tr>
                    <td>Decision Tree</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.485 ± 0.036</td>
                </tr>
                <tr>
                    <td>K-Nearest Neighbors</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.460</td>
                    <td>0.459</td>
                    <td>0.455</td>
                    <td>0.519 ± 0.016</td>
                </tr>
                <tr>
                    <td>Naive Bayes</td>
                    <td>0.465</td>
                    <td>0.463</td>
                    <td>0.465</td>
                    <td>0.458</td>
                    <td>0.470</td>
                    <td>0.483 ± 0.030</td>
                </tr>
            </tbody>
        </table>

        <div class="results-box">
            <strong>نتیجه کلیدی:</strong> مدل شبکه عصبی با F1-Score برابر 0.520 بهترین عملکرد را داشت، اگرچه این دقت نشان‌دهنده نیاز به بهبود بیشتر مدل‌ها است.
        </div>

        <h3>۵.۲ نتایج خوشه‌بندی</h3>

        <table>
            <thead>
                <tr>
                    <th>الگوریتم</th>
                    <th>Silhouette Score</th>
                    <th>Davies-Bouldin</th>
                    <th>Calinski-Harabasz</th>
                    <th>تعداد خوشه‌ها</th>
                </tr>
            </thead>
            <tbody>
                <tr style="background-color: #d4edda;">
                    <td><strong>GMM</strong></td>
                    <td><strong>0.4161</strong></td>
                    <td><strong>1.499</strong></td>
                    <td>56.43</td>
                    <td>2</td>
                </tr>
                <tr>
                    <td>K-Means</td>
                    <td>0.1397</td>
                    <td>2.498</td>
                    <td><strong>145.12</strong></td>
                    <td>2</td>
                </tr>
                <tr>
                    <td>DBSCAN</td>
                    <td>0.1342</td>
                    <td>2.643</td>
                    <td>87.49</td>
                    <td>2 (+ 37 نویز)</td>
                </tr>
                <tr>
                    <td>Hierarchical</td>
                    <td>0.1229</td>
                    <td>2.704</td>
                    <td>119.41</td>
                    <td>2</td>
                </tr>
            </tbody>
        </table>

        <h4>تحلیل خوشه‌ها</h4>
        <table>
            <thead>
                <tr>
                    <th>خوشه</th>
                    <th>تعداد دانش‌آموزان</th>
                    <th>درصد</th>
                    <th>نرخ قبولی</th>
                    <th>ویژگی‌های برجسته</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>خوشه 1</td>
                    <td>451</td>
                    <td>45.1%</td>
                    <td>52.3%</td>
                    <td>حضور متوسط، مطالعه متوسط، نمره قبلی بالاتر</td>
                </tr>
                <tr>
                    <td>خوشه 2</td>
                    <td>549</td>
                    <td>54.9%</td>
                    <td>48.3%</td>
                    <td>حضور متوسط، مطالعه متوسط، نمره قبلی پایین‌تر</td>
                </tr>
            </tbody>
        </table>

        <div class="warning-box">
            <strong>نکته مهم:</strong> Adjusted Rand Index (0.0006) و Adjusted Mutual Information (0.0005) پایین نشان می‌دهند که خوشه‌های شناسایی شده ارتباط ضعیفی با برچسب‌های واقعی قبول/رد دارند.
        </div>

        <h3>۵.۳ نتایج قوانین همبستگی</h3>

        <div class="results-box">
            <strong>خلاصه نتایج:</strong>
            <ul>
                <li>تعداد کل قوانین استخراج شده: <span class="highlight">13,885</span></li>
                <li>قوانین قوی (Confidence ≥ 0.7, Lift > 1.2): <span class="highlight">431</span></li>
                <li>قوانین منتهی به قبولی: 1,657</li>
                <li>قوانین منتهی به رد: 1,633</li>
                <li>بالاترین Lift: <span class="highlight">4.717</span></li>
            </ul>
        </div>

        <h4>قوی‌ترین قوانین کشف شده</h4>
        
        <p><strong>قانون با بالاترین Lift (4.717):</strong></p>
        <div style="background-color: #f8f9fa; padding: 10px; border-radius: 5px; margin: 10px 0;">
            <strong>IF:</strong> Attendance_Level=Low AND Previous_Performance=Poor AND Gender=Female<br>
            <strong>THEN:</strong> Activities_Level=Low AND Cluster_1 AND Pass_Result=Fail<br>
            <strong>Support:</strong> 0.011 | <strong>Confidence:</strong> 0.500 | <strong>Lift:</strong> 4.717
        </div>

        <h4>عوامل کلیدی موثر بر قبولی</h4>
        <ul>
            <li><strong>عوامل مثبت:</strong> حضور بالا، ساعات مطالعه زیاد، عملکرد قبلی خوب، حمایت بالای والدین</li>
            <li><strong>عوامل منفی:</strong> حضور پایین، مطالعه کم، عملکرد قبلی ضعیف، حمایت پایین والدین</li>
        </ul>

        <!-- تحلیل و بحث -->
        <h2>۶. تحلیل و بحث</h2>

        <h3>۶.۱ تحلیل عملکرد مدل‌های طبقه‌بندی</h3>
        <p>
            نتایج نشان می‌دهد که مدل‌های طبقه‌بندی عملکرد متوسطی دارند با حداکثر F1-Score برابر 0.52. این عملکرد نسبتاً پایین می‌تواند به دلایل زیر باشد:
        </p>
        <ul>
            <li><strong>پیچیدگی ذاتی مسئله:</strong> عملکرد تحصیلی تحت تأثیر عوامل متعدد و پیچیده‌ای است که ممکن است همه آنها در داده‌ها موجود نباشند</li>
            <li><strong>کیفیت داده‌ها:</strong> احتمال وجود نویز در داده‌ها یا عدم کفایت ویژگی‌های موجود</li>
            <li><strong>توزیع متوازن کلاس‌ها:</strong> با وجود توزیع 50-50، ممکن است الگوهای تمایز واضحی بین دو کلاس وجود نداشته باشد</li>
            <li><strong>روابط غیرخطی پیچیده:</strong> حتی شبکه عصبی که قابلیت مدل‌سازی روابط پیچیده را دارد، نتوانست دقت بالایی کسب کند</li>
        </ul>

        <h3>۶.۲ تحلیل نتایج خوشه‌بندی</h3>
        <p>
            الگوریتم GMM با Silhouette Score برابر 0.4161 بهترین عملکرد را داشت که نشان‌دهنده کیفیت متوسط خوشه‌بندی است. نکات کلیدی:
        </p>
        <ul>
            <li>تعداد بهینه خوشه‌ها (2) ممکن است برای تمایز کامل دانش‌آموزان کافی نباشد</li>
            <li>عدم ارتباط قوی خوشه‌ها با برچسب‌های قبول/رد (ARI=0.0006) نشان می‌دهد که الگوهای طبیعی در داده‌ها لزوماً با وضعیت قبولی/رد منطبق نیستند</li>
            <li>GMM به دلیل انعطاف‌پذیری در شکل خوشه‌ها، عملکرد بهتری نسبت به K-Means داشت</li>
        </ul>

        <h3>۶.۳ تحلیل قوانین همبستگی</h3>
        <p>
            استخراج 13,885 قانون نشان‌دهنده روابط پیچیده بین ویژگی‌ها است. تحلیل قوانین قوی نشان می‌دهد:
        </p>
        <ul>
            <li><strong>اهمیت حضور در کلاس:</strong> حضور پایین قوی‌ترین پیش‌بینی‌کننده شکست تحصیلی است</li>
            <li><strong>تأثیر عملکرد قبلی:</strong> عملکرد ضعیف قبلی با احتمال بالای رد در آینده همراه است</li>
            <li><strong>نقش حمایت والدین:</strong> حمایت پایین والدین در ترکیب با سایر عوامل منفی، احتمال رد را افزایش می‌دهد</li>
            <li><strong>تفاوت‌های جنسیتی:</strong> برخی قوانین نشان می‌دهند که الگوهای موفقیت/شکست در دختران و پسران متفاوت است</li>
        </ul>

        <h3>۶.۴ محدودیت‌های پژوهش</h3>
        <ol>
            <li><strong>محدودیت داده‌ها:</strong>
                <ul>
                    <li>حجم نسبتاً کم داده‌ها (1000 نمونه)</li>
                    <li>احتمال عدم پوشش همه عوامل موثر (مثل وضعیت اقتصادی، سلامت روانی)</li>
                </ul>
            </li>
            <li><strong>محدودیت‌های روش‌شناسی:</strong>
                <ul>
                    <li>استفاده از میانه برای تعیین آستانه قبولی ممکن است واقع‌بینانه نباشد</li>
                    <li>عدم استفاده از روش‌های Deep Learning پیشرفته‌تر</li>
                </ul>
            </li>
            <li><strong>محدودیت‌های تعمیم‌پذیری:</strong>
                <ul>
                    <li>نتایج ممکن است به سایر محیط‌های آموزشی قابل تعمیم نباشد</li>
                </ul>
            </li>
        </ol>

        <!-- اعتبارسنجی آماری -->
        <h2>۷. اعتبارسنجی آماری نتایج</h2>

        <h3>۷.۱ آزمون Friedman برای مقایسه مدل‌ها</h3>
        <p>
            برای بررسی معناداری تفاوت بین عملکرد مدل‌های طبقه‌بندی، از آزمون Friedman استفاده شد:
        </p>
        <div class="results-box">
            <ul>
                <li><strong>Friedman Statistic:</strong> 30.9873</li>
                <li><strong>P-value:</strong> 0.000141</li>
                <li><strong>نتیجه:</strong> با p-value < 0.05، تفاوت معناداری بین عملکرد مدل‌ها وجود دارد ✓</li>
            </ul>
        </div>

        <h3>۷.۲ فاصله اطمینان 95% برای معیارهای ارزیابی</h3>
        <table>
            <thead>
                <tr>
                    <th>معیار</th>
                    <th>میانگین</th>
                    <th>فاصله اطمینان 95%</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Accuracy</td>
                    <td>0.4856</td>
                    <td>[0.4671, 0.5040]</td>
                </tr>
                <tr>
                    <td>Precision</td>
                    <td>0.4852</td>
                    <td>[0.4666, 0.5039]</td>
                </tr>
                <tr>
                    <td>Recall</td>
                    <td>0.4856</td>
                    <td>[0.4671, 0.5040]</td>
                </tr>
                <tr>
                    <td>F1-Score</td>
                    <td>0.4842</td>
                    <td>[0.4650, 0.5033]</td>
                </tr>
            </tbody>
        </table>

        <h3>۷.۳ رتبه‌بندی نهایی روش‌ها</h3>
        <p>بر اساس امتیاز ترکیبی محاسبه شده:</p>
        <table>
            <thead>
                <tr>
                    <th>رتبه</th>
                    <th>روش</th>
                    <th>امتیاز ترکیبی</th>
                    <th>وضعیت</th>
                </tr>
            </thead>
            <tbody>
                <tr style="background-color: #ffd700;">
                    <td>🥇 1</td>
                    <td>Clustering</td>
                    <td>0.5315</td>
                    <td>خوب</td>
                </tr>
                <tr style="background-color: #c0c0c0;">
                    <td>🥈 2</td>
                    <td>Classification</td>
                    <td>0.4859</td>
                    <td>متوسط</td>
                </tr>
                <tr style="background-color: #cd7f32;">
                    <td>🥉 3</td>
                    <td>Association Rules</td>
                    <td>0.4186</td>
                    <td>متوسط</td>
                </tr>
            </tbody>
        </table>

        <!-- پیشنهادات برای بهبود -->
        <h2>۸. پیشنهادات برای بهبود</h2>

        <h3>۸.۱ بهبود مدل‌های طبقه‌بندی</h3>
        <ol>
            <li><strong>استفاده از روش‌های Ensemble Learning:</strong> پیاده‌سازی Stacking یا Voting Classifier برای ترکیب نقاط قوت مدل‌های مختلف</li>
            <li><strong>بهینه‌سازی عمیق‌تر Hyperparameters:</strong> استفاده از Bayesian Optimization یا Grid Search گسترده‌تر</li>
            <li><strong>مهندسی ویژگی:</strong> ایجاد ویژگی‌های ترکیبی جدید و استفاده از تکنیک‌های انتخاب ویژگی</li>
            <li><strong>تنظیم Threshold:</strong> بهینه‌سازی آستانه تصمیم‌گیری برای متوازن کردن Precision و Recall</li>
        </ol>

        <h3>۸.۲ بهبود خوشه‌بندی</h3>
        <ol>
            <li><strong>کاهش ابعاد موثرتر:</strong> استفاده از t-SNE یا UMAP به جای PCA</li>
            <li><strong>آزمایش معیارهای فاصله مختلف:</strong> Manhattan Distance یا Cosine Similarity</li>
            <li><strong>خوشه‌بندی سلسله‌مراتبی:</strong> بررسی تعداد خوشه‌های بیشتر برای تمایز بهتر</li>
            <li><strong>Semi-supervised Clustering:</strong> استفاده از برچسب‌های موجود برای هدایت خوشه‌بندی</li>
        </ol>

        <h3>۸.۳ بهبود قوانین همبستگی</h3>
        <ol>
            <li><strong>تنظیم پارامترها:</strong> کاهش حد آستانه Support برای کشف قوانین نادر اما مهم</li>
            <li><strong>Pruning قوانین:</strong> حذف قوانین redundant و نگهداری قوانین با بیشترین ارزش اطلاعاتی</li>
            <li><strong>قوانین چندسطحی:</strong> بررسی قوانین با طول بیشتر برای کشف روابط پیچیده‌تر</li>
        </ol>

        <!-- نتیجه‌گیری -->
        <h2>۹. نتیجه‌گیری</h2>

        <h3>۹.۱ خلاصه نتایج</h3>
        <p>
            این پژوهش با هدف توسعه یک سیستم جامع پیش‌بینی عملکرد تحصیلی دانش‌آموزان، از ترکیب سه رویکرد اصلی داده‌کاوی استفاده کرد. نتایج کلیدی عبارتند از:
        </p>
        <ul>
            <li>مدل شبکه عصبی با F1-Score برابر 0.52 بهترین عملکرد را در طبقه‌بندی داشت</li>
            <li>الگوریتم GMM با Silhouette Score برابر 0.4161 بهترین نتیجه خوشه‌بندی را ارائه داد</li>
            <li>13,885 قانون همبستگی استخراج شد که 431 قانون قوی شناسایی شدند</li>
            <li>عوامل کلیدی موثر بر عملکرد تحصیلی شامل حضور در کلاس، ساعات مطالعه، عملکرد قبلی و حمایت والدین هستند</li>
        </ul>

        <h3>۹.۲ دستاوردهای علمی</h3>
        <p>
            این پژوهش نشان داد که:
        </p>
        <ol>
            <li>پیش‌بینی عملکرد تحصیلی یک مسئله پیچیده است که نیازمند رویکردهای چندگانه است</li>
            <li>ترکیب روش‌های مختلف داده‌کاوی می‌تواند دیدگاه جامع‌تری از عوامل موثر ارائه دهد</li>
            <li>قوانین همبستگی می‌توانند بینش‌های قابل تفسیری برای مربیان فراهم کنند</li>
            <li>خوشه‌بندی می‌تواند در شناسایی گروه‌های همگن دانش‌آموزان برای برنامه‌ریزی آموزشی هدفمند مفید باشد</li>
        </ol>

        <h3>۹.۳ کاربردهای عملی</h3>
        <p>
            نتایج این پژوهش می‌تواند کاربردهای عملی زیر را داشته باشد:
        </p>
        <ul>
            <li><strong>سیستم هشدار زودهنگام:</strong> شناسایی دانش‌آموزان در معرض خطر در ابتدای ترم تحصیلی</li>
            <li><strong>برنامه‌ریزی آموزشی شخصی‌سازی شده:</strong> طراحی برنامه‌های حمایتی متناسب با نیاز هر گروه</li>
            <li><strong>تخصیص بهینه منابع:</strong> اولویت‌بندی تخصیص منابع آموزشی به دانش‌آموزان نیازمند</li>
            <li><strong>مشاوره تحصیلی هدفمند:</strong> ارائه توصیه‌های مبتنی بر داده به دانش‌آموزان و والدین</li>
        </ul>

        <h3>۹.۴ پیشنهادات برای تحقیقات آینده</h3>
        <ol>
            <li><strong>جمع‌آوری داده‌های بیشتر:</strong> افزایش حجم نمونه و افزودن ویژگی‌های جدید مانند وضعیت اقتصادی-اجتماعی، سلامت روانی، و سبک یادگیری</li>
            <li><strong>استفاده از Deep Learning:</strong> پیاده‌سازی معماری‌های پیشرفته مانند LSTM برای تحلیل داده‌های سری زمانی عملکرد تحصیلی</li>
            <li><strong>رویکرد Multi-Task Learning:</strong> پیش‌بینی همزمان چندین جنبه از عملکرد تحصیلی</li>
            <li><strong>تحلیل علّی:</strong> استفاده از روش‌های Causal Inference برای شناسایی روابط علت و معلولی</li>
            <li><strong>مطالعات طولی:</strong> پیگیری عملکرد دانش‌آموزان در طول زمان برای درک بهتر روند تغییرات</li>
        </ol>

        <div class="warning-box">
            <strong>نکته پایانی:</strong> با وجود عملکرد متوسط مدل‌ها (عملکرد کلی سیستم: 0.4787)، این پژوهش پایه‌ای مناسب برای توسعه سیستم‌های پیشرفته‌تر پیش‌بینی عملکرد تحصیلی فراهم می‌کند. بهبود مستمر این سیستم‌ها می‌تواند نقش مهمی در ارتقای کیفیت آموزش و کاهش نرخ افت تحصیلی داشته باشد.
        </div>

        <!-- منابع -->
        <div class="references">
            <h2>۱۰. منابع</h2>
            
            <div class="reference-item">
                [1] Romero, C., & Ventura, S. (2020). Educational data mining and learning analytics: An updated survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 10(3), e1355.
            </div>
            
            <div class="reference-item">
                [2] Kumar, M., & Pal, R. (2021). Prediction of student's performance using machine learning algorithms. International Journal of Advanced Computer Science and Applications, 12(7), 243-252.
            </div>
            
            <div class="reference-item">
                [3] Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.
            </div>
            
            <div class="reference-item">
                [4] Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3), 273-297.
            </div>
            
            <div class="reference-item">
                [5] MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability (Vol. 1, No. 14, pp. 281-297).
            </div>
            
            <div class="reference-item">
                [6] Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996). A density-based algorithm for discovering clusters in large spatial databases with noise. In Kdd (Vol. 96, No. 34, pp. 226-231).
            </div>
            
            <div class="reference-item">
                [7] McLachlan, G., & Peel, D. (2000). Finite mixture models. John Wiley & Sons.
            </div>
            
            <div class="reference-item">
                [8] Agrawal, R., & Srikant, R. (1994). Fast algorithms for mining association rules. In Proc. 20th int. conf. very large data bases, VLDB (Vol. 1215, pp. 487-499).
            </div>
            
            <div class="reference-item">
                [9] Han, J., Pei, J., & Yin, Y. (2000). Mining frequent patterns without candidate generation. ACM sigmod record, 29(2), 1-12.
            </div>
            
            <div class="reference-item">
                [10] Friedman, M. (1937). The use of ranks to avoid the assumption of normality implicit in the analysis of variance. Journal of the american statistical association, 32(200), 675-701.
            </div>
            
            <div class="reference-item">
                [11] Rousseeuw, P. J. (1987). Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. Journal of computational and applied mathematics, 20, 53-65.
            </div>
            
            <div class="reference-item">
                [12] Davies, D. L., & Bouldin, D. W. (1979). A cluster separation measure. IEEE transactions on pattern analysis and machine intelligence, (2), 224-227.
            </div>
            
            <div class="reference-item">
                [13] Caliński, T., & Harabasz, J. (1974). A dendrite method for cluster analysis. Communications in Statistics-theory and Methods, 3(1), 1-27.
            </div>
            
            <div class="reference-item">
                [14] Hubert, L., & Arabie, P. (1985). Comparing partitions. Journal of classification, 2(1), 193-218.
            </div>
            
            <div class="reference-item">
                [15] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... & Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), 2825-2830.
            </div>
        </div>

        <!-- پیوست‌ها -->
        <div style="margin-top: 40px; padding-top: 20px; border-top: 2px solid #ddd;">
            <h2>۱۱. پیوست‌ها</h2>
            
            <h3>پیوست الف: نمونه کد پایتون برای پیش‌پردازش داده‌ها</h3>
            <div style="background-color: #f5f5f5; padding: 15px; border-radius: 5px; font-family: monospace; font-size: 14px;">
                <pre>
# بارگذاری کتابخانه‌ها
import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# بارگذاری داده‌ها
df = pd.read_csv('student_performance.csv')

# پردازش مقادیر گمشده
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for col in numerical_columns:
    df[col].fillna(df[col].mean(), inplace=True)

# کدگذاری متغیرهای دسته‌ای
le = LabelEncoder()
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    df[col + '_Encoded'] = le.fit_transform(df[col])

# نرمال‌سازی
scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

# تقسیم داده‌ها
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
                </pre>
            </div>

            <h3>پیوست ب: جدول معیارهای ارزیابی تفصیلی</h3>
            <table>
                <thead>
                    <tr>
                        <th>معیار</th>
                        <th>فرمول</th>
                        <th>محدوده</th>
                        <th>تفسیر</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Accuracy</td>
                        <td>(TP + TN) / (TP + TN + FP + FN)</td>
                        <td>[0, 1]</td>
                        <td>نسبت پیش‌بینی‌های صحیح</td>
                    </tr>
                    <tr>
                        <td>Precision</td>
                        <td>TP / (TP + FP)</td>
                        <td>[0, 1]</td>
                        <td>دقت در پیش‌بینی‌های مثبت</td>
                    </tr>
                    <tr>
                        <td>Recall</td>
                        <td>TP / (TP + FN)</td>
                        <td>[0, 1]</td>
                        <td>پوشش موارد مثبت واقعی</td>
                    </tr>
                    <tr>
                        <td>F1-Score</td>
                        <td>2 × (Precision × Recall) / (Precision + Recall)</td>
                        <td>[0, 1]</td>
                        <td>میانگین هارمونیک دقت و بازخوانی</td>
                    </tr>
                    <tr>
                        <td>Silhouette Score</td>
                        <td>(b - a) / max(a, b)</td>
                        <td>[-1, 1]</td>
                        <td>کیفیت خوشه‌بندی</td>
                    </tr>
                    <tr>
                        <td>Support</td>
                        <td>freq(X,Y) / N</td>
                        <td>[0, 1]</td>
                        <td>فراوانی نسبی آیتم‌ست</td>
                    </tr>
                    <tr>
                        <td>Confidence</td>
                        <td>freq(X,Y) / freq(X)</td>
                        <td>[0, 1]</td>
                        <td>احتمال شرطی</td>
                    </tr>
                    <tr>
                        <td>Lift</td>
                        <td>Confidence(X→Y) / Support(Y)</td>
                        <td>[0, ∞)</td>
                        <td>قدرت قانون</td>
                    </tr>
                </tbody>
            </table>

            <h3>پیوست ج: لیست فایل‌های خروجی پروژه</h3>
            <ul>
                <li><strong>processed_student_data.csv:</strong> داده‌های پردازش شده نهایی</li>
                <li><strong>train_data.csv:</strong> مجموعه داده آموزشی</li>
                <li><strong>test_data.csv:</strong> مجموعه داده تست</li>
                <li><strong>best_model.pkl:</strong> بهترین مدل طبقه‌بندی ذخیره شده</li>
                <li><strong>clustering_results.pkl:</strong> نتایج کامل خوشه‌بندی</li>
                <li><strong>association_rules_all.csv:</strong> تمام قوانین همبستگی استخراج شده</li>
                <li><strong>model_comparison_charts.png:</strong> نمودارهای مقایسه مدل‌ها</li>
                <li><strong>confusion_matrices_all.png:</strong> ماتریس‌های درهم‌ریختگی</li>
                <li><strong>roc_curves.png:</strong> منحنی‌های ROC</li>
                <li><strong>elbow_silhouette_analysis.png:</strong> تحلیل Elbow و Silhouette</li>
                <li><strong>clustering_visualization.png:</strong> نمایش خوشه‌ها</li>
                <li><strong>final_evaluation_report.txt:</strong> گزارش نهایی ارزیابی</li>
            </ul>
        </div>

        <!-- پایان مقاله -->
        <div style="margin-top: 50px; padding: 20px; background-color: #e3f2fd; border-radius: 10px; text-align: center;">
            <h3>پایان مقاله</h3>
            <p style="font-style: italic;">
                این مقاله بر اساس پروژه داده‌کاوی آموزشی با هدف پیش‌بینی عملکرد تحصیلی دانش‌آموزان تهیه شده است.
            </p>
            <p>
                <strong>تاریخ تکمیل:</strong> شهریور ۱۴۰۴<br>
                <strong>حجم داده:</strong> ۱۰۰۰ رکورد<br>
                <strong>تعداد ویژگی:</strong> ۱۷ ویژگی<br>
                <strong>روش‌های استفاده شده:</strong> Classification, Clustering, Association Rules
            </p>
        </div>
    </div>
</body>
</html>