# Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ù¾Ø±ÙˆÚ˜Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†
# Ù†Ø³Ø®Ù‡ Ø®Ù„Ø§ØµÙ‡ Ø¨Ø±Ø§ÛŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø³Ø±ÛŒØ¹ Ù†ØªØ§ÛŒØ¬

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score, f1_score, silhouette_score
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ù¾Ø±ÙˆÚ˜Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†")
print("=" * 60)

# 1. Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø³Øª Ù†Ù…ÙˆÙ†Ù‡
print("ğŸ“Š Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø³Øª...")
np.random.seed(42)
n = 1000

data = {
    'Hours_Studied': np.random.normal(7, 3, n).clip(1, 20),
    'Previous_Scores': np.random.normal(75, 15, n).clip(40, 100),
    'Sleep_Hours': np.random.normal(7, 1.5, n).clip(4, 12),
    'Extracurricular': np.random.choice([0, 1], n, p=[0.4, 0.6]),
    'Parental_Support': np.random.choice([0, 1, 2], n, p=[0.3, 0.4, 0.3]),  # Low, Medium, High
    'Resource_Access': np.random.choice([0, 1, 2], n, p=[0.25, 0.5, 0.25])
}

df = pd.DataFrame(data)

# Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
def create_target(row):
    score = (row['Hours_Studied'] * 3 + 
             row['Previous_Scores'] * 0.4 + 
             row['Sleep_Hours'] * 2 + 
             row['Extracurricular'] * 10 + 
             row['Parental_Support'] * 8 + 
             row['Resource_Access'] * 6 + 
             np.random.normal(0, 5))
    
    if score < 50:
        return 0  # Poor
    elif score < 80:
        return 1  # Average
    else:
        return 2  # Excellent

df['Performance'] = df.apply(create_target, axis=1)
performance_names = {0: 'Poor', 1: 'Average', 2: 'Excellent'}

print(f"âœ… Ø¯ÛŒØªØ§Ø³Øª {len(df)} Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
print(f"ğŸ“Š ØªÙˆØ²ÛŒØ¹ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
for k, v in pd.Series(df['Performance']).map(performance_names).value_counts().items():
    print(f"   {k}: {v} Ù†ÙØ± ({v/len(df)*100:.1f}%)")

# 2. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø³Ø±ÛŒØ¹
print(f"\nğŸ”§ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´...")
X = df.drop('Performance', axis=1)
y = df['Performance']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯: {len(X_train)} Ø¢Ù…ÙˆØ²Ø´ÛŒØŒ {len(X_test)} ØªØ³Øª")

# 3. Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
print(f"\nğŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§...")

models = {
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=50)
}

results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    results[name] = {'accuracy': accuracy, 'f1': f1}
    print(f"   {name}: Accuracy={accuracy:.3f}, F1={f1:.3f}")

# Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
best_model = max(results.keys(), key=lambda x: results[x]['f1'])
print(f"\nğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model} (F1={results[best_model]['f1']:.3f})")

# 4. Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø±ÛŒØ¹
print(f"\nğŸ”— Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ...")

# ØªØ³Øª Ú†Ù†Ø¯ ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡
silhouette_scores = []
k_range = range(2, 6)

for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(X_scaled)
    score = silhouette_score(X_scaled, labels)
    silhouette_scores.append(score)
    print(f"   K={k}: Silhouette Score={score:.3f}")

best_k = k_range[np.argmax(silhouette_scores)]
print(f"\nğŸ¯ Ø¨Ù‡ØªØ±ÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡: {best_k}")

# Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)
clusters = kmeans_final.fit_predict(X_scaled)

# ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
print(f"\nğŸ“Š ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§:")
df['Cluster'] = clusters

for cluster_id in range(best_k):
    cluster_data = df[df['Cluster'] == cluster_id]
    dominant_performance = cluster_data['Performance'].mode().iloc[0]
    performance_name = performance_names[dominant_performance]
    
    print(f"   Ø®ÙˆØ´Ù‡ {cluster_id}: {len(cluster_data)} Ù†ÙØ± - Ø¹Ù…Ù„Ú©Ø±Ø¯ ØºØ§Ù„Ø¨: {performance_name}")
    print(f"      Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¹Øª Ù…Ø·Ø§Ù„Ø¹Ù‡: {cluster_data['Hours_Studied'].mean():.1f}")
    print(f"      Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ù…Ø±Ù‡ Ù‚Ø¨Ù„ÛŒ: {cluster_data['Previous_Scores'].mean():.1f}")

# 5. Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒØ¯ÛŒ
print(f"\nğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒØ¯ÛŒ:")

# Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø³Ø§Ø¯Ù‡
correlations = df[['Hours_Studied', 'Previous_Scores', 'Sleep_Hours', 'Performance']].corr()['Performance'].sort_values(ascending=False)

print(f"ğŸ”— Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
for feature, corr in correlations.items():
    if feature != 'Performance':
        print(f"   {feature}: {corr:.3f}")

# Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ù‡Ø± Ú¯Ø±ÙˆÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯
print(f"\nğŸ“Š Ù…Ø´Ø®ØµØ§Øª Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
performance_stats = df.groupby('Performance').agg({
    'Hours_Studied': 'mean',
    'Previous_Scores': 'mean',
    'Sleep_Hours': 'mean',
    'Extracurricular': 'mean'
}).round(1)

for perf_id, stats in performance_stats.iterrows():
    perf_name = performance_names[perf_id]
    count = (df['Performance'] == perf_id).sum()
    print(f"   {perf_name} ({count} Ù†ÙØ±):")
    print(f"      Ø³Ø§Ø¹Øª Ù…Ø·Ø§Ù„Ø¹Ù‡: {stats['Hours_Studied']}")
    print(f"      Ù†Ù…Ø±Ù‡ Ù‚Ø¨Ù„ÛŒ: {stats['Previous_Scores']}")
    print(f"      Ø³Ø§Ø¹Øª Ø®ÙˆØ§Ø¨: {stats['Sleep_Hours']}")
    print(f"      ÙØ¹Ø§Ù„ÛŒØª ÙÙˆÙ‚â€ŒØ¨Ø±Ù†Ø§Ù…Ù‡: {stats['Extracurricular']*100:.0f}%")

# 6. Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ
print(f"\nğŸ¯ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ:")
print(f"âœ… Ø¯Ù‚Øª Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {results[best_model]['accuracy']*100:.1f}%")
print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: {best_k}")
print(f"âœ… Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ: {correlations.iloc[1]:.3f} ({correlations.index[1]})")

# Ø¹ÙˆØ§Ù…Ù„ Ú©Ù„ÛŒØ¯ÛŒ Ù…ÙˆÙÙ‚ÛŒØª
top_performers = df[df['Performance'] == 2]  # Excellent
if len(top_performers) > 0:
    print(f"\nğŸŒŸ Ù…Ø´Ø®ØµØ§Øª Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù† Ø¨Ø±ØªØ± ({len(top_performers)} Ù†ÙØ±):")
    print(f"   Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¹Øª Ù…Ø·Ø§Ù„Ø¹Ù‡: {top_performers['Hours_Studied'].mean():.1f}")
    print(f"   Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ù…Ø±Ù‡ Ù‚Ø¨Ù„ÛŒ: {top_performers['Previous_Scores'].mean():.1f}")
    print(f"   Ø¯Ø±ØµØ¯ ÙØ¹Ø§Ù„ÛŒØª ÙÙˆÙ‚â€ŒØ¨Ø±Ù†Ø§Ù…Ù‡: {top_performers['Extracurricular'].mean()*100:.0f}%")

print(f"\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª:")
if correlations['Hours_Studied'] > 0.3:
    print(f"   ğŸ“š Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø§Ø¹Ø§Øª Ù…Ø·Ø§Ù„Ø¹Ù‡ ØªØ£Ø«ÛŒØ± Ù…Ø«Ø¨Øª Ø¯Ø§Ø±Ø¯")
if correlations['Previous_Scores'] > 0.5:
    print(f"   ğŸ“Š Ù†Ù…Ø±Ø§Øª Ù‚Ø¨Ù„ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù‚ÙˆÛŒ Ù‡Ø³ØªÙ†Ø¯")
if correlations['Sleep_Hours'] > 0.1:
    print(f"   ğŸ˜´ Ø®ÙˆØ§Ø¨ Ù…Ù†Ø§Ø³Ø¨ Ù…Ù‡Ù… Ø§Ø³Øª")

print(f"\nğŸ‰ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÛŒØ¹ Ù¾Ø±ÙˆÚ˜Ù‡ ØªÙ…Ø§Ù… Ø´Ø¯!")
print("=" * 60)

# Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø³Ø±ÛŒØ¹
df.to_csv('quick_results.csv', index=False)
print(f"ğŸ’¾ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± 'quick_results.csv' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
