#!/usr/bin/env python3
"""
Ù¾Ø±ÙˆÚ˜Ù‡ Ú©Ø§Ù…Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†
Ø´Ø§Ù…Ù„: Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒØŒ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒØŒ Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ

Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø±Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÚ©Ø§ÙˆÛŒ
ØªØ§Ø±ÛŒØ®: 1404
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, silhouette_score
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import warnings
warnings.filterwarnings('ignore')

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ Ú©Ø§Ù…Ù„ Ù¾Ø±ÙˆÚ˜Ù‡"""
    
    print("ğŸ“ Ù¾Ø±ÙˆÚ˜Ù‡ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†")
    print("=" * 60)
    
    # Ù…Ø±Ø­Ù„Ù‡ 1: Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df, X_train, X_test, y_train, y_test, X_encoded, scaler = create_and_preprocess_data()
    
    # Ù…Ø±Ø­Ù„Ù‡ 2: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    model_results, best_model_name = train_classification_models(X_train, X_test, y_train, y_test)
    
    # Ù…Ø±Ø­Ù„Ù‡ 3: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    cluster_results = perform_clustering(df)
    
    # Ù…Ø±Ø­Ù„Ù‡ 4: Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ
    association_results = extract_association_rules(df)
    
    # Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    final_evaluation(df, model_results, cluster_results, association_results, best_model_name)
    
    print("\nğŸ‰ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")

def create_and_preprocess_data():
    """Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
    print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 1: Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    
    np.random.seed(42)
    n_students = 1500
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø¯ÛŒØªØ§Ø³Øª
    data = {
        'Hours_Studied': np.random.normal(7, 3, n_students).clip(1, 20),
        'Previous_Scores': np.random.normal(75, 15, n_students).clip(40, 100),
        'Extracurricular_Activities': np.random.choice([0, 1], n_students, p=[0.4, 0.6]),
        'Sleep_Hours': np.random.normal(7, 1.5, n_students).clip(4, 12),
        'Sample_Question_Papers_Practiced': np.random.randint(0, 10, n_students),
        'Performance_Index': np.random.normal(50, 20, n_students).clip(10, 100)
    }
    
    df = pd.DataFrame(data)
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
    df['Gender'] = np.random.choice(['Male', 'Female'], n_students)
    df['Parental_Involvement'] = np.random.choice(['Low', 'Medium', 'High'], n_students, p=[0.3, 0.4, 0.3])
    df['Access_to_Resources'] = np.random.choice(['Low', 'Medium', 'High'], n_students, p=[0.25, 0.5, 0.25])
    df['Motivation_Level'] = np.random.choice(['Low', 'Medium', 'High'], n_students, p=[0.2, 0.6, 0.2])
    df['Internet_Access'] = np.random.choice(['Yes', 'No'], n_students, p=[0.85, 0.15])
    df['Family_Income'] = np.random.choice(['Low', 'Medium', 'High'], n_students, p=[0.3, 0.5, 0.2])
    df['Teacher_Quality'] = np.random.choice(['Low', 'Medium', 'High'], n_students, p=[0.2, 0.6, 0.2])
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù
    def calculate_performance_category(row):
        score = 0
        score += row['Hours_Studied'] * 3
        score += row['Previous_Scores'] * 0.4
        score += row['Extracurricular_Activities'] * 8
        
        if 6 <= row['Sleep_Hours'] <= 8:
            score += 10
        
        score += row['Sample_Question_Papers_Practiced'] * 2
        
        # ØªØ£Ø«ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
        if row['Parental_Involvement'] == 'High':
            score += 15
        elif row['Parental_Involvement'] == 'Medium':
            score += 8
            
        if row['Access_to_Resources'] == 'High':
            score += 12
        elif row['Access_to_Resources'] == 'Medium':
            score += 6
            
        if row['Motivation_Level'] == 'High':
            score += 10
        elif row['Motivation_Level'] == 'Medium':
            score += 5
            
        score += np.random.normal(0, 5)
        
        if score < 50:
            return 0  # Poor
        elif score < 80:
            return 1  # Average
        else:
            return 2  # Excellent
    
    df['Performance_Category'] = df.apply(calculate_performance_category, axis=1)
    performance_labels = {0: 'Poor', 1: 'Average', 2: 'Excellent'}
    df['Performance_Label'] = df['Performance_Category'].map(performance_labels)
    
    print(f"âœ… Ø¯ÛŒØªØ§Ø³Øª Ø¨Ø§ {len(df)} Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ² Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    print(f"ğŸ“ˆ ØªÙˆØ²ÛŒØ¹ Ø¹Ù…Ù„Ú©Ø±Ø¯: {df['Performance_Label'].value_counts().to_dict()}")
    
    # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
    features_for_modeling = ['Hours_Studied', 'Previous_Scores', 'Extracurricular_Activities', 
                            'Sleep_Hours', 'Sample_Question_Papers_Practiced', 'Gender', 
                            'Parental_Involvement', 'Access_to_Resources', 'Motivation_Level',
                            'Internet_Access', 'Family_Income', 'Teacher_Quality']
    
    X = df[features_for_modeling].copy()
    y = df['Performance_Category']
    
    # Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ One-Hot
    categorical_features = ['Gender', 'Parental_Involvement', 'Access_to_Resources', 'Motivation_Level',
                           'Internet_Access', 'Family_Income', 'Teacher_Quality']
    X_encoded = pd.get_dummies(X, columns=categorical_features, prefix=categorical_features)
    
    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ
    numerical_features = ['Hours_Studied', 'Previous_Scores', 'Sleep_Hours', 'Sample_Question_Papers_Practiced', 'Extracurricular_Activities']
    scaler = StandardScaler()
    X_encoded[numerical_features] = scaler.fit_transform(X_encoded[numerical_features])
    
    # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)
    
    print(f"âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„ - Ø¢Ù…ÙˆØ²Ø´ÛŒ: {len(X_train)}, ØªØ³Øª: {len(X_test)}")
    
    # Ø°Ø®ÛŒØ±Ù‡
    df.to_csv('student_performance_dataset.csv', index=False)
    
    return df, X_train, X_test, y_train, y_test, X_encoded, scaler

def train_classification_models(X_train, X_test, y_train, y_test):
    """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ"""
    print("\nğŸ¤– Ù…Ø±Ø­Ù„Ù‡ 2: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ...")
    
    models = {
        'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),
        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
        'SVM': SVC(random_state=42, probability=True, kernel='rbf'),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
    }
    
    model_results = {}
    
    for model_name, model in models.items():
        print(f"ğŸ”„ Ø¢Ù…ÙˆØ²Ø´ {model_name}...")
        
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        
        model_results[model_name] = {
            'model': model,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'cv_mean': cv_scores.mean(),
            'y_pred': y_pred
        }
        
        print(f"   âœ… F1-Score: {f1:.4f}, CV: {cv_scores.mean():.4f}")
    
    # Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„
    best_model_name = max(model_results.keys(), key=lambda x: model_results[x]['f1'])
    print(f"\nğŸ† Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
    
    return model_results, best_model_name

def perform_clustering(df):
    """Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†"""
    print("\nğŸ”— Ù…Ø±Ø­Ù„Ù‡ 3: Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ...")
    
    clustering_features = ['Hours_Studied', 'Previous_Scores', 'Sleep_Hours', 'Sample_Question_Papers_Practiced']
    X_clustering = df[clustering_features].copy()
    
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_clustering)
    
    # ØªØ¹ÛŒÛŒÙ† ØªØ¹Ø¯Ø§Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡ Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
    silhouette_scores = []
    k_range = range(2, 8)
    
    for k in k_range:
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels = kmeans.fit_predict(X_scaled)
        score = silhouette_score(X_scaled, labels)
        silhouette_scores.append(score)
    
    best_k = k_range[np.argmax(silhouette_scores)]
    
    # Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    kmeans_final = KMeans(n_clusters=best_k, random_state=42, n_init=10)
    cluster_labels = kmeans_final.fit_predict(X_scaled)
    
    df_with_clusters = df.copy()
    df_with_clusters['Cluster'] = cluster_labels
    
    print(f"âœ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ {best_k} Ø®ÙˆØ´Ù‡ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
    print(f"ğŸ“Š Silhouette Score: {silhouette_score(X_scaled, cluster_labels):.4f}")
    
    # Ø°Ø®ÛŒØ±Ù‡
    df_with_clusters.to_csv('students_with_clusters.csv', index=False)
    
    return {
        'best_k': best_k,
        'silhouette_score': silhouette_score(X_scaled, cluster_labels),
        'cluster_labels': cluster_labels,
        'df_with_clusters': df_with_clusters
    }

def extract_association_rules(df):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ"""
    print("\nğŸ”— Ù…Ø±Ø­Ù„Ù‡ 4: Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ...")
    
    try:
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
        df_rules = df.copy()
        
        df_rules['Study_Hours_Cat'] = pd.cut(df['Hours_Studied'], bins=[0, 5, 10, 20], labels=['Ú©Ù…', 'Ù…ØªÙˆØ³Ø·', 'Ø²ÛŒØ§Ø¯'])
        df_rules['Previous_Scores_Cat'] = pd.cut(df['Previous_Scores'], bins=[0, 60, 80, 100], labels=['Ø¶Ø¹ÛŒÙ', 'Ù…ØªÙˆØ³Ø·', 'Ø¹Ø§Ù„ÛŒ'])
        df_rules['Sleep_Cat'] = pd.cut(df['Sleep_Hours'], bins=[0, 6, 8, 12], labels=['Ú©Ù…', 'Ù…Ù†Ø§Ø³Ø¨', 'Ø²ÛŒØ§Ø¯'])
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§
        features_for_rules = ['Study_Hours_Cat', 'Previous_Scores_Cat', 'Sleep_Cat', 
                             'Parental_Involvement', 'Access_to_Resources', 'Performance_Label']
        
        transactions = []
        for idx, row in df_rules.iterrows():
            transaction = []
            for feature in features_for_rules:
                if pd.notna(row[feature]):
                    transaction.append(f"{feature}_{row[feature]}")
            transactions.append(transaction)
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ù†Ø§Ø³Ø¨
        te = TransactionEncoder()
        te_ary = te.fit(transactions).transform(transactions)
        df_transactions = pd.DataFrame(te_ary, columns=te.columns_)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø±
        frequent_itemsets = apriori(df_transactions, min_support=0.1, use_colnames=True)
        
        if len(frequent_itemsets) > 0:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙˆØ§Ù†ÛŒÙ†
            rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.3)
            
            if len(rules) > 0:
                rules_sorted = rules.sort_values('lift', ascending=False)
                print(f"âœ… {len(rules)} Ù‚Ø§Ù†ÙˆÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ ÛŒØ§ÙØª Ø´Ø¯")
                
                return {
                    'rules_count': len(rules),
                    'best_lift': rules['lift'].max(),
                    'avg_confidence': rules['confidence'].mean(),
                    'rules': rules_sorted
                }
            else:
                print("âŒ Ù‡ÛŒÚ† Ù‚Ø§Ù†ÙˆÙ†ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                return {'rules_count': 0}
        else:
            print("âŒ Ù‡ÛŒÚ† Ø§Ù„Ú¯ÙˆÛŒ Ù¾Ø±ØªÚ©Ø±Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return {'rules_count': 0}
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙˆØ§Ù†ÛŒÙ†: {e}")
        return {'rules_count': 0}

def final_evaluation(df, model_results, cluster_results, association_results, best_model_name):
    """Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ú¯Ø²Ø§Ø±Ø´"""
    print("\nğŸ“Š Ù…Ø±Ø­Ù„Ù‡ 5: Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ...")
    
    # Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
    print("=" * 60)
    print("ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ù†Ù‡Ø§ÛŒÛŒ Ù¾Ø±ÙˆÚ˜Ù‡")
    print("=" * 60)
    
    print(f"ğŸ“Š Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯ÛŒØªØ§Ø³Øª:")
    print(f"   â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø§Ù†Ø´â€ŒØ¢Ù…ÙˆØ²Ø§Ù†: {len(df)}")
    print(f"   â€¢ ØªÙˆØ²ÛŒØ¹ Ø¹Ù…Ù„Ú©Ø±Ø¯: {df['Performance_Label'].value_counts().to_dict()}")
    
    print(f"\nğŸ¤– Ù†ØªØ§ÛŒØ¬ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:")
    print(f"   â€¢ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…Ø¯Ù„: {best_model_name}")
    print(f"   â€¢ F1-Score: {model_results[best_model_name]['f1']:.4f}")
    print(f"   â€¢ Accuracy: {model_results[best_model_name]['accuracy']:.4f}")
    
    print(f"\nğŸ”— Ù†ØªØ§ÛŒØ¬ Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ:")
    print(f"   â€¢ ØªØ¹Ø¯Ø§Ø¯ Ø®ÙˆØ´Ù‡ Ø¨Ù‡ÛŒÙ†Ù‡: {cluster_results['best_k']}")
    print(f"   â€¢ Silhouette Score: {cluster_results['silhouette_score']:.4f}")
    
    print(f"\nğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ:")
    print(f"   â€¢ ØªØ¹Ø¯Ø§Ø¯ Ù‚ÙˆØ§Ù†ÛŒÙ†: {association_results['rules_count']}")
    if association_results['rules_count'] > 0:
        print(f"   â€¢ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Lift: {association_results['best_lift']:.3f}")
        print(f"   â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø¹ØªÙ…Ø§Ø¯: {association_results['avg_confidence']:.3f}")
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§
    results_df = pd.DataFrame({
        'Model': list(model_results.keys()),
        'Accuracy': [model_results[m]['accuracy'] for m in model_results.keys()],
        'Precision': [model_results[m]['precision'] for m in model_results.keys()],
        'Recall': [model_results[m]['recall'] for m in model_results.keys()],
        'F1-Score': [model_results[m]['f1'] for m in model_results.keys()],
        'CV_Mean': [model_results[m]['cv_mean'] for m in model_results.keys()]
    })
    
    print(f"\nğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù…Ø¯Ù„â€ŒÙ‡Ø§:")
    print(results_df.round(4).to_string(index=False))
    
    # ØªØ­Ù„ÛŒÙ„ Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø±
    print(f"\nğŸ” Ø¹ÙˆØ§Ù…Ù„ Ù…Ø¤Ø«Ø± Ø¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯:")
    
    # Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Performance_Index
    numeric_features = ['Hours_Studied', 'Previous_Scores', 'Sleep_Hours', 'Sample_Question_Papers_Practiced']
    correlations = df[numeric_features + ['Performance_Index']].corr()['Performance_Index'].sort_values(ascending=False)
    
    print("   ğŸ“Š Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Ø´Ø§Ø®Øµ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
    for feature, corr in correlations.items():
        if feature != 'Performance_Index':
            print(f"      â€¢ {feature}: {corr:.3f}")
    
    # ØªØ­Ù„ÛŒÙ„ Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
    print(f"\nğŸ“ˆ Ù…Ø´Ø®ØµØ§Øª Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯:")
    for label in ['Poor', 'Average', 'Excellent']:
        group = df[df['Performance_Label'] == label]
        if len(group) > 0:
            print(f"   ğŸ”¸ {label} ({len(group)} Ù†ÙØ±):")
            print(f"      â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø§Ø¹Øª Ù…Ø·Ø§Ù„Ø¹Ù‡: {group['Hours_Studied'].mean():.1f}")
            print(f"      â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù†Ù…Ø±Ù‡ Ù‚Ø¨Ù„ÛŒ: {group['Previous_Scores'].mean():.1f}")
            print(f"      â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø®ÙˆØ§Ø¨: {group['Sleep_Hours'].mean():.1f}")
    
    # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª
    print(f"\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:")
    print("   1ï¸âƒ£ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø§Ø¹Ø§Øª Ù…Ø·Ø§Ù„Ø¹Ù‡ Ù…Ø¤Ø«Ø±ØªØ±ÛŒÙ† Ø¹Ø§Ù…Ù„ Ø§Ø³Øª")
    print("   2ï¸âƒ£ Ù†Ù…Ø±Ø§Øª Ù‚Ø¨Ù„ÛŒ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ù‚ÙˆÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢ÛŒÙ†Ø¯Ù‡ Ù‡Ø³ØªÙ†Ø¯")
    print("   3ï¸âƒ£ Ø®ÙˆØ§Ø¨ Ù…Ù†Ø§Ø³Ø¨ (6-8 Ø³Ø§Ø¹Øª) Ø­Ø§Ø¦Ø² Ø§Ù‡Ù…ÛŒØª Ø§Ø³Øª")
    print("   4ï¸âƒ£ Ø¯Ø±Ú¯ÛŒØ±ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ† Ùˆ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ Ù†Ù‚Ø´ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø§Ø±Ù†Ø¯")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ
    results_df.to_csv('model_comparison_results.csv', index=False)
    
    # Ø¢Ù…Ø§Ø± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§
    if 'df_with_clusters' in cluster_results:
        cluster_stats = cluster_results['df_with_clusters'].groupby('Cluster').agg({
            'Hours_Studied': 'mean',
            'Previous_Scores': 'mean',
            'Performance_Label': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Mixed'
        }).round(2)
        
        print(f"\nğŸ”— Ø¢Ù…Ø§Ø± Ø®ÙˆØ´Ù‡â€ŒÙ‡Ø§:")
        print(cluster_stats.to_string())
    
    print(f"\nâœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ:")
    print(f"   ğŸ“„ student_performance_dataset.csv")
    print(f"   ğŸ“„ students_with_clusters.csv") 
    print(f"   ğŸ“„ model_comparison_results.csv")
    
    print(f"\nğŸ¯ Ù¾Ø±ÙˆÚ˜Ù‡ Ø´Ø§Ù…Ù„ Ù…ÙˆØ§Ø±Ø¯ Ø²ÛŒØ± Ø¨ÙˆØ¯:")
    print(f"   âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
    print(f"   âœ… 4 Ù…Ø¯Ù„ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ Cross-Validation")
    print(f"   âœ… Ø®ÙˆØ´Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ K-Means")
    print(f"   âœ… Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø§ Apriori")
    print(f"   âœ… Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬")

# Ù†Ù‚Ø·Ù‡ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡: {e}")
        print("ğŸ’¡ Ù„Ø·ÙØ§Ù‹ Ù…Ø·Ù…Ø¦Ù† Ø´ÙˆÛŒØ¯ Ú©Ù‡ ØªÙ…Ø§Ù… Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ù†ØµØ¨ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯")

# Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§:
"""
pip install pandas numpy matplotlib seaborn scikit-learn mlxtend

ÛŒØ§ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Ù‡Ù…Ù‡:
pip install -r requirements.txt

Ù…Ø­ØªÙˆÛŒØ§Øª requirements.txt:
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
mlxtend>=0.19.0
"""
