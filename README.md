::: container
# پیش‌بینی عملکرد تحصیلی دانش‌آموزان با استفاده از تکنیک‌های ترکیبی داده‌کاوی: رویکردی جامع با Classification، Clustering و Association Rules

::: author-info
پروژه داده‌کاوی - سالار لطفی , نازنین خاکسبز\
تاریخ: شهریور ۱۴۰۴
:::

::: abstract
## چکیده

پیش‌بینی عملکرد تحصیلی دانش‌آموزان یکی از چالش‌های مهم در حوزه آموزش است که
می‌تواند به شناسایی زودهنگام دانش‌آموزان در معرض خطر افت تحصیلی کمک کند.
این پژوهش با هدف توسعه یک سیستم جامع پیش‌بینی عملکرد تحصیلی، از ترکیب سه
رویکرد اصلی داده‌کاوی شامل طبقه‌بندی (Classification)، خوشه‌بندی
(Clustering) و قوانین همبستگی (Association Rules) استفاده می‌کند. داده‌های
مورد استفاده شامل ۱۰۰۰ رکورد از دانش‌آموزان با ۱۷ ویژگی مختلف است. در فاز
طبقه‌بندی، ۹ الگوریتم مختلف پیاده‌سازی شد که مدل شبکه عصبی با F1-Score
برابر ۰.۵۲ بهترین عملکرد را داشت. در فاز خوشه‌بندی، الگوریتم GMM با
Silhouette Score برابر ۰.۴۱۶۱ بهترین نتیجه را ارائه داد. همچنین ۱۳,۸۸۵
قانون همبستگی استخراج شد که ۴۳۱ قانون قوی با Confidence بالای ۰.۷
شناسایی شدند. نتایج نشان می‌دهد که عوامل کلیدی موثر بر عملکرد تحصیلی شامل
نرخ حضور، ساعات مطالعه، عملکرد قبلی و حمایت والدین هستند.

::: keywords
**کلمات کلیدی:** داده‌کاوی آموزشی، پیش‌بینی عملکرد دانش‌آموزان، طبقه‌بندی،
خوشه‌بندی، قوانین همبستگی، یادگیری ماشین
:::
:::

## ۱. مقدمه

### ۱.۱ بیان مسئله

سیستم‌های آموزشی در سراسر جهان با چالش شناسایی و پشتیبانی از دانش‌آموزانی
که در معرض خطر افت تحصیلی قرار دارند، مواجه هستند. پیش‌بینی زودهنگام
عملکرد تحصیلی می‌تواند به مربیان و مدیران آموزشی کمک کند تا مداخلات
هدفمند و به‌موقع را طراحی و اجرا کنند. با توجه به حجم عظیم داده‌های آموزشی
موجود، استفاده از تکنیک‌های داده‌کاوی می‌تواند الگوهای پنهان و عوامل موثر
بر موفقیت یا شکست تحصیلی را آشکار سازد.

### ۱.۲ اهمیت موضوع

اهمیت این پژوهش از چند منظر قابل بررسی است. از نظر علمی، این مطالعه
رویکردی ترکیبی و جامع برای تحلیل داده‌های آموزشی ارائه می‌دهد که می‌تواند
به توسعه دانش در حوزه Educational Data Mining کمک کند. از منظر عملی،
نتایج این پژوهش می‌تواند به بهبود کیفیت آموزش، کاهش نرخ افت تحصیلی، و
بهینه‌سازی تخصیص منابع آموزشی منجر شود. همچنین، شناسایی عوامل کلیدی موثر
بر عملکرد تحصیلی می‌تواند در طراحی برنامه‌های آموزشی شخصی‌سازی شده مورد
استفاده قرار گیرد.

### ۱.۳ اهداف و سوالات تحقیق

هدف اصلی این پژوهش، توسعه یک سیستم جامع و دقیق برای پیش‌بینی عملکرد
تحصیلی دانش‌آموزان با استفاده از تکنیک‌های مختلف داده‌کاوی است. سوالات اصلی
تحقیق عبارتند از:

-   کدام الگوریتم طبقه‌بندی بهترین عملکرد را در پیش‌بینی وضعیت قبولی/رد
    دانش‌آموزان دارد؟
-   آیا می‌توان دانش‌آموزان را بر اساس ویژگی‌های تحصیلی و رفتاری در گروه‌های
    همگن دسته‌بندی کرد؟
-   چه قوانین همبستگی قوی بین ویژگی‌های مختلف و عملکرد تحصیلی وجود دارد؟
-   کدام عوامل بیشترین تاثیر را بر موفقیت یا شکست تحصیلی دانش‌آموزان
    دارند؟

### ۱.۴ ساختار گزارش

این گزارش در ۱۱ بخش سازماندهی شده است. پس از مقدمه، بخش ۲ به مرور ادبیات
موضوع می‌پردازد. بخش ۳ داده‌ها و ویژگی‌های آنها را توصیف می‌کند. بخش ۴ روش‌ها
و الگوریتم‌های استفاده شده را تشریح می‌کند. بخش‌های ۵ تا ۷ به ترتیب نتایج،
تحلیل و بحث را ارائه می‌دهند. بخش ۸ اعتبارسنجی آماری نتایج را بررسی می‌کند
و در نهایت، بخش ۹ نتیجه‌گیری و پیشنهادات را ارائه می‌دهد.

## ۲. مرور ادبیات

### ۲.۱ مطالعات پیشین

در سال‌های اخیر، مطالعات متعددی در زمینه پیش‌بینی عملکرد تحصیلی با استفاده
از تکنیک‌های داده‌کاوی انجام شده است. Romero و Ventura (2020) در مطالعه
جامع خود، بیش از ۳۰۰ مقاله در حوزه Educational Data Mining را مرور کردند
و نشان دادند که الگوریتم‌های طبقه‌بندی، به‌ویژه Decision Trees و Neural
Networks، پرکاربردترین روش‌ها در این حوزه هستند. Kumar و Pal (2021) با
استفاده از الگوریتم Naive Bayes توانستند با دقت ۷۸٪ عملکرد دانشجویان را
پیش‌بینی کنند.

### ۲.۲ مفاهیم اصلی

#### ۲.۲.۱ الگوریتم‌های طبقه‌بندی

طبقه‌بندی یکی از تکنیک‌های اصلی یادگیری با نظارت است که هدف آن پیش‌بینی
برچسب کلاس برای نمونه‌های جدید بر اساس الگوهای آموخته شده از داده‌های
آموزشی است. در این پژوهش، از الگوریتم‌های مختلفی شامل:

-   **شبکه‌های عصبی مصنوعی (Neural Networks):** مدل‌هایی الهام‌گرفته از مغز
    انسان که قابلیت یادگیری الگوهای پیچیده غیرخطی را دارند
-   **ماشین بردار پشتیبان (SVM):** الگوریتمی که با یافتن ابرصفحه بهینه،
    داده‌ها را در فضای چندبعدی جدا می‌کند
-   **جنگل تصادفی (Random Forest):** روش ensemble که از ترکیب چندین درخت
    تصمیم برای بهبود دقت استفاده می‌کند
-   **رگرسیون لجستیک:** مدل آماری برای پیش‌بینی احتمال وقوع یک رویداد
    دودویی

#### ۲.۲.۲ الگوریتم‌های خوشه‌بندی

خوشه‌بندی یک تکنیک یادگیری بدون نظارت است که هدف آن گروه‌بندی داده‌ها بر
اساس شباهت‌های ذاتی است. الگوریتم‌های استفاده شده شامل:

-   **K-Means:** الگوریتمی که داده‌ها را به K خوشه تقسیم می‌کند با هدف
    حداقل‌سازی واریانس درون‌خوشه‌ای
-   **DBSCAN:** روشی مبتنی بر چگالی که قابلیت شناسایی خوشه‌های با شکل
    دلخواه را دارد
-   **GMM (Gaussian Mixture Model):** مدل احتمالاتی که فرض می‌کند داده‌ها
    از ترکیب چند توزیع گاوسی تولید شده‌اند
-   **Hierarchical Clustering:** روشی که ساختار سلسله‌مراتبی خوشه‌ها را
    ایجاد می‌کند

#### ۲.۲.۳ قوانین همبستگی

کشف قوانین همبستگی به دنبال یافتن روابط جالب بین متغیرها در پایگاه‌های
داده بزرگ است. دو الگوریتم اصلی استفاده شده عبارتند از:

-   **Apriori:** الگوریتم کلاسیک که با استفاده از رویکرد bottom-up،
    مجموعه‌های پرتکرار را شناسایی می‌کند
-   **FP-Growth:** الگوریتم بهینه‌تر که با ساخت درخت FP، نیاز به اسکن‌های
    متعدد پایگاه داده را کاهش می‌دهد

## ۳. داده‌ها و ویژگی‌های آنها

### ۳.۱ منبع و توصیف داده‌ها

مجموعه داده مورد استفاده در این پژوهش شامل اطلاعات ۱۰۰۰ دانش‌آموز با ۱۷
ویژگی مختلف است. این داده‌ها از فایل CSV با نام
\"student_performance_updated_1000.csv\" بارگذاری شده‌اند. داده‌ها شامل
ترکیبی از ویژگی‌های عددی و دسته‌ای هستند که جنبه‌های مختلف عملکرد تحصیلی و
ویژگی‌های دموگرافیک دانش‌آموزان را پوشش می‌دهند.

### ۳.۲ ویژگی‌های داده‌ها

  نام ویژگی                   نوع            توضیحات                     محدوده/مقادیر
  --------------------------- -------------- --------------------------- -----------------
  StudentID                   عددی           شناسه یکتای دانش‌آموز        1-1000
  Gender                      دسته‌ای         جنسیت دانش‌آموز              Male/Female
  AttendanceRate              عددی           نرخ حضور در کلاس            0-100%
  StudyHoursPerWeek           عددی           ساعات مطالعه هفتگی          0-40 ساعت
  PreviousGrade               عددی           نمره دوره قبلی              0-100
  ExtracurricularActivities   عددی           میزان فعالیت‌های فوق‌برنامه   0-10
  ParentalSupport             دسته‌ای         سطح حمایت والدین            Low/Medium/High
  FinalGrade                  عددی           نمره نهایی                  0-100
  Pass_Status                 دسته‌ای (هدف)   وضعیت قبولی/رد              Pass/Fail

### ۳.۳ پیش‌پردازش داده‌ها

فرآیند پیش‌پردازش داده‌ها شامل مراحل زیر بود:

1.  **پردازش مقادیر گمشده:** مقادیر گمشده در ویژگی‌های عددی با میانگین و
    در ویژگی‌های دسته‌ای با مد (پرتکرارترین مقدار) جایگزین شدند
2.  **ایجاد متغیر هدف:** بر اساس میانه نمرات نهایی، دانش‌آموزان به دو
    گروه قبول و رد تقسیم شدند
3.  **کدگذاری متغیرهای دسته‌ای:** با استفاده از LabelEncoder، متغیرهای
    دسته‌ای به مقادیر عددی تبدیل شدند
4.  **نرمال‌سازی:** ویژگی‌های عددی با استفاده از StandardScaler نرمال‌سازی
    شدند تا میانگین صفر و انحراف معیار یک داشته باشند
5.  **تقسیم داده‌ها:** داده‌ها با نسبت 80-20 به مجموعه‌های آموزشی (800
    نمونه) و تست (200 نمونه) تقسیم شدند

::: results-box
**نتیجه پیش‌پردازش:** پس از اتمام پیش‌پردازش، تمامی مقادیر گمشده پردازش
شدند و توزیع متوازنی از کلاس‌های قبول (50.1%) و رد (49.9%) حاصل شد.
:::

## ۴. روش‌ها و الگوریتم‌ها

### ۴.۱ فاز طبقه‌بندی (Classification)

در این فاز، ۹ الگوریتم مختلف طبقه‌بندی پیاده‌سازی و مقایسه شدند:

#### ۴.۱.۱ شبکه عصبی مصنوعی (MLP Classifier)

شبکه عصبی پیاده‌سازی شده از نوع Multilayer Perceptron با پارامترهای زیر
بود:

-   تعداد لایه‌های پنهان: 2 لایه با 100 نورون
-   تابع فعال‌سازی: ReLU
-   الگوریتم بهینه‌سازی: Adam
-   نرخ یادگیری: 0.001
-   حداکثر تکرار: 1000

#### ۴.۱.۲ ماشین بردار پشتیبان (SVM)

دو نوع SVM پیاده‌سازی شد:

-   **SVM خطی:** با kernel=\'linear\' برای جداسازی خطی داده‌ها
-   **SVM با کرنل RBF:** برای مدل‌سازی روابط غیرخطی پیچیده

#### ۴.۱.۳ روش‌های Ensemble

-   **Random Forest:** با 100 درخت تصمیم و عمق نامحدود
-   **Gradient Boosting:** با 100 estimator و نرخ یادگیری 0.1

### ۴.۲ فاز خوشه‌بندی (Clustering)

#### ۴.۲.۱ تعیین تعداد بهینه خوشه‌ها

برای تعیین تعداد بهینه خوشه‌ها از دو روش استفاده شد:

1.  **روش Elbow:** با بررسی WCSS (Within-Cluster Sum of Squares) برای K
    از 2 تا 10
2.  **Silhouette Score:** برای ارزیابی کیفیت خوشه‌بندی

::: figure
**شکل 1:** نمودار Elbow و Silhouette Score

بر اساس تحلیل‌ها، تعداد بهینه خوشه‌ها برابر با 2 تعیین شد
:::

#### ۴.۲.۲ الگوریتم‌های خوشه‌بندی

  الگوریتم       پارامترهای کلیدی         ویژگی‌های خاص
  -------------- ------------------------ ------------------------------------------
  K-Means        K=2, n_init=10           سرعت بالا، خوشه‌های کروی
  DBSCAN         eps=1.9, min_samples=5   شناسایی نقاط نویز، خوشه‌های با شکل دلخواه
  GMM            n_components=2           مدل احتمالاتی، انعطاف‌پذیری بالا
  Hierarchical   linkage=\'ward\'         ساختار سلسله‌مراتبی، dendrogram

### ۴.۳ فاز قوانین همبستگی (Association Rules)

#### ۴.۳.۱ آماده‌سازی داده‌ها

برای استخراج قوانین همبستگی، ابتدا ویژگی‌های پیوسته به دسته‌ای تبدیل شدند:

-   **AttendanceRate:** به سه دسته Low، Medium و High تقسیم شد
-   **StudyHoursPerWeek:** به سه سطح Low_Study، Medium_Study و
    High_Study
-   **PreviousGrade:** به Poor، Average و Good تبدیل شد
-   **ExtracurricularActivities:** به Low، Medium و High Activities

#### ۴.۳.۲ پارامترهای الگوریتم‌ها

-   **حداقل Support:** 0.01 (حداقل 1% از تراکنش‌ها)
-   **حداقل Confidence:** 0.5 (50% اطمینان)
-   **حداکثر طول قانون:** 5 آیتم

### ۴.۴ معیارهای ارزیابی

#### ۴.۴.۱ معیارهای طبقه‌بندی

-   **Accuracy:** نسبت پیش‌بینی‌های صحیح به کل پیش‌بینی‌ها
-   **Precision:** نسبت پیش‌بینی‌های مثبت صحیح به کل پیش‌بینی‌های مثبت
-   **Recall:** نسبت پیش‌بینی‌های مثبت صحیح به کل موارد واقعاً مثبت
-   **F1-Score:** میانگین هارمونیک Precision و Recall
-   **AUC-ROC:** سطح زیر منحنی ROC

::: equation
F1-Score = 2 × (Precision × Recall) / (Precision + Recall)
:::

#### ۴.۴.۲ معیارهای خوشه‌بندی

-   **Silhouette Score:** معیاری بین -1 تا 1 که کیفیت خوشه‌بندی را نشان
    می‌دهد
-   **Davies-Bouldin Index:** نسبت شباهت درون‌خوشه‌ای به بین‌خوشه‌ای (کمتر
    بهتر)
-   **Calinski-Harabasz Score:** نسبت پراکندگی بین‌خوشه‌ای به درون‌خوشه‌ای
    (بیشتر بهتر)

#### ۴.۴.۳ معیارهای قوانین همبستگی

-   **Support:** فراوانی نسبی آیتم‌ست در کل تراکنش‌ها
-   **Confidence:** احتمال وقوع consequent به شرط وقوع antecedent
-   **Lift:** نسبت Confidence واقعی به Confidence مورد انتظار در حالت
    استقلال

## ۵. نتایج

### ۵.۱ نتایج طبقه‌بندی

  مدل                   Accuracy    Precision   Recall      F1-Score    AUC         CV Mean ± Std
  --------------------- ----------- ----------- ----------- ----------- ----------- -------------------
  **Neural Network**    **0.520**   **0.520**   **0.520**   **0.520**   **0.519**   **0.513 ± 0.017**
  SVM (RBF)             0.520       0.520       0.520       0.520       0.545       0.516 ± 0.047
  Random Forest         0.510       0.510       0.510       0.510       0.488       0.533 ± 0.015
  Logistic Regression   0.490       0.490       0.490       0.489       0.508       0.509 ± 0.042
  Gradient Boosting     0.480       0.480       0.480       0.479       0.478       0.526 ± 0.009
  SVM (Linear)          0.465       0.465       0.465       0.464       0.474       0.519 ± 0.027
  Decision Tree         0.460       0.460       0.460       0.460       0.460       0.485 ± 0.036
  K-Nearest Neighbors   0.460       0.460       0.460       0.459       0.455       0.519 ± 0.016
  Naive Bayes           0.465       0.463       0.465       0.458       0.470       0.483 ± 0.030

::: results-box
**نتیجه کلیدی:** مدل شبکه عصبی با F1-Score برابر 0.520 بهترین عملکرد را
داشت، اگرچه این دقت نشان‌دهنده نیاز به بهبود بیشتر مدل‌ها است.
:::

### ۵.۲ نتایج خوشه‌بندی

  الگوریتم       Silhouette Score   Davies-Bouldin   Calinski-Harabasz   تعداد خوشه‌ها
  -------------- ------------------ ---------------- ------------------- ---------------
  **GMM**        **0.4161**         **1.499**        56.43               2
  K-Means        0.1397             2.498            **145.12**          2
  DBSCAN         0.1342             2.643            87.49               2 (+ 37 نویز)
  Hierarchical   0.1229             2.704            119.41              2

#### تحلیل خوشه‌ها

  خوشه     تعداد دانش‌آموزان   درصد    نرخ قبولی   ویژگی‌های برجسته
  -------- ------------------ ------- ----------- ---------------------------------------------
  خوشه 1   451                45.1%   52.3%       حضور متوسط، مطالعه متوسط، نمره قبلی بالاتر
  خوشه 2   549                54.9%   48.3%       حضور متوسط، مطالعه متوسط، نمره قبلی پایین‌تر

::: warning-box
**نکته مهم:** Adjusted Rand Index (0.0006) و Adjusted Mutual Information
(0.0005) پایین نشان می‌دهند که خوشه‌های شناسایی شده ارتباط ضعیفی با
برچسب‌های واقعی قبول/رد دارند.
:::

### ۵.۳ نتایج قوانین همبستگی

::: results-box
**خلاصه نتایج:**

-   تعداد کل قوانین استخراج شده: [13,885]{.highlight}
-   قوانین قوی (Confidence ≥ 0.7, Lift \> 1.2): [431]{.highlight}
-   قوانین منتهی به قبولی: 1,657
-   قوانین منتهی به رد: 1,633
-   بالاترین Lift: [4.717]{.highlight}
:::

#### قوی‌ترین قوانین کشف شده

**قانون با بالاترین Lift (4.717):**

::: {style="background-color: #f8f9fa; padding: 10px; border-radius: 5px; margin: 10px 0;"}
**IF:** Attendance_Level=Low AND Previous_Performance=Poor AND
Gender=Female\
**THEN:** Activities_Level=Low AND Cluster_1 AND Pass_Result=Fail\
**Support:** 0.011 \| **Confidence:** 0.500 \| **Lift:** 4.717
:::

#### عوامل کلیدی موثر بر قبولی

-   **عوامل مثبت:** حضور بالا، ساعات مطالعه زیاد، عملکرد قبلی خوب، حمایت
    بالای والدین
-   **عوامل منفی:** حضور پایین، مطالعه کم، عملکرد قبلی ضعیف، حمایت پایین
    والدین

## ۶. تحلیل و بحث

### ۶.۱ تحلیل عملکرد مدل‌های طبقه‌بندی

نتایج نشان می‌دهد که مدل‌های طبقه‌بندی عملکرد متوسطی دارند با حداکثر
F1-Score برابر 0.52. این عملکرد نسبتاً پایین می‌تواند به دلایل زیر باشد:

-   **پیچیدگی ذاتی مسئله:** عملکرد تحصیلی تحت تأثیر عوامل متعدد و
    پیچیده‌ای است که ممکن است همه آنها در داده‌ها موجود نباشند
-   **کیفیت داده‌ها:** احتمال وجود نویز در داده‌ها یا عدم کفایت ویژگی‌های
    موجود
-   **توزیع متوازن کلاس‌ها:** با وجود توزیع 50-50، ممکن است الگوهای تمایز
    واضحی بین دو کلاس وجود نداشته باشد
-   **روابط غیرخطی پیچیده:** حتی شبکه عصبی که قابلیت مدل‌سازی روابط
    پیچیده را دارد، نتوانست دقت بالایی کسب کند

### ۶.۲ تحلیل نتایج خوشه‌بندی

الگوریتم GMM با Silhouette Score برابر 0.4161 بهترین عملکرد را داشت که
نشان‌دهنده کیفیت متوسط خوشه‌بندی است. نکات کلیدی:

-   تعداد بهینه خوشه‌ها (2) ممکن است برای تمایز کامل دانش‌آموزان کافی
    نباشد
-   عدم ارتباط قوی خوشه‌ها با برچسب‌های قبول/رد (ARI=0.0006) نشان می‌دهد که
    الگوهای طبیعی در داده‌ها لزوماً با وضعیت قبولی/رد منطبق نیستند
-   GMM به دلیل انعطاف‌پذیری در شکل خوشه‌ها، عملکرد بهتری نسبت به K-Means
    داشت

### ۶.۳ تحلیل قوانین همبستگی

استخراج 13,885 قانون نشان‌دهنده روابط پیچیده بین ویژگی‌ها است. تحلیل
قوانین قوی نشان می‌دهد:

-   **اهمیت حضور در کلاس:** حضور پایین قوی‌ترین پیش‌بینی‌کننده شکست تحصیلی
    است
-   **تأثیر عملکرد قبلی:** عملکرد ضعیف قبلی با احتمال بالای رد در آینده
    همراه است
-   **نقش حمایت والدین:** حمایت پایین والدین در ترکیب با سایر عوامل
    منفی، احتمال رد را افزایش می‌دهد
-   **تفاوت‌های جنسیتی:** برخی قوانین نشان می‌دهند که الگوهای موفقیت/شکست
    در دختران و پسران متفاوت است

### ۶.۴ محدودیت‌های پژوهش

1.  **محدودیت داده‌ها:**
    -   حجم نسبتاً کم داده‌ها (1000 نمونه)
    -   احتمال عدم پوشش همه عوامل موثر (مثل وضعیت اقتصادی، سلامت روانی)
2.  **محدودیت‌های روش‌شناسی:**
    -   استفاده از میانه برای تعیین آستانه قبولی ممکن است واقع‌بینانه
        نباشد
    -   عدم استفاده از روش‌های Deep Learning پیشرفته‌تر
3.  **محدودیت‌های تعمیم‌پذیری:**
    -   نتایج ممکن است به سایر محیط‌های آموزشی قابل تعمیم نباشد

## ۷. اعتبارسنجی آماری نتایج

### ۷.۱ آزمون Friedman برای مقایسه مدل‌ها

برای بررسی معناداری تفاوت بین عملکرد مدل‌های طبقه‌بندی، از آزمون Friedman
استفاده شد:

::: results-box
-   **Friedman Statistic:** 30.9873
-   **P-value:** 0.000141
-   **نتیجه:** با p-value \< 0.05، تفاوت معناداری بین عملکرد مدل‌ها وجود
    دارد ✓
:::

### ۷.۲ فاصله اطمینان 95% برای معیارهای ارزیابی

  معیار       میانگین   فاصله اطمینان 95%
  ----------- --------- --------------------
  Accuracy    0.4856    \[0.4671, 0.5040\]
  Precision   0.4852    \[0.4666, 0.5039\]
  Recall      0.4856    \[0.4671, 0.5040\]
  F1-Score    0.4842    \[0.4650, 0.5033\]

### ۷.۳ رتبه‌بندی نهایی روش‌ها

بر اساس امتیاز ترکیبی محاسبه شده:

  رتبه   روش                 امتیاز ترکیبی   وضعیت
  ------ ------------------- --------------- -------
  🥇 1   Clustering          0.5315          خوب
  🥈 2   Classification      0.4859          متوسط
  🥉 3   Association Rules   0.4186          متوسط

## ۸. پیشنهادات برای بهبود

### ۸.۱ بهبود مدل‌های طبقه‌بندی

1.  **استفاده از روش‌های Ensemble Learning:** پیاده‌سازی Stacking یا
    Voting Classifier برای ترکیب نقاط قوت مدل‌های مختلف
2.  **بهینه‌سازی عمیق‌تر Hyperparameters:** استفاده از Bayesian
    Optimization یا Grid Search گسترده‌تر
3.  **مهندسی ویژگی:** ایجاد ویژگی‌های ترکیبی جدید و استفاده از تکنیک‌های
    انتخاب ویژگی
4.  **تنظیم Threshold:** بهینه‌سازی آستانه تصمیم‌گیری برای متوازن کردن
    Precision و Recall

### ۸.۲ بهبود خوشه‌بندی

1.  **کاهش ابعاد موثرتر:** استفاده از t-SNE یا UMAP به جای PCA
2.  **آزمایش معیارهای فاصله مختلف:** Manhattan Distance یا Cosine
    Similarity
3.  **خوشه‌بندی سلسله‌مراتبی:** بررسی تعداد خوشه‌های بیشتر برای تمایز بهتر
4.  **Semi-supervised Clustering:** استفاده از برچسب‌های موجود برای هدایت
    خوشه‌بندی

### ۸.۳ بهبود قوانین همبستگی

1.  **تنظیم پارامترها:** کاهش حد آستانه Support برای کشف قوانین نادر اما
    مهم
2.  **Pruning قوانین:** حذف قوانین redundant و نگهداری قوانین با بیشترین
    ارزش اطلاعاتی
3.  **قوانین چندسطحی:** بررسی قوانین با طول بیشتر برای کشف روابط
    پیچیده‌تر

## ۹. نتیجه‌گیری

### ۹.۱ خلاصه نتایج

این پژوهش با هدف توسعه یک سیستم جامع پیش‌بینی عملکرد تحصیلی دانش‌آموزان،
از ترکیب سه رویکرد اصلی داده‌کاوی استفاده کرد. نتایج کلیدی عبارتند از:

-   مدل شبکه عصبی با F1-Score برابر 0.52 بهترین عملکرد را در طبقه‌بندی
    داشت
-   الگوریتم GMM با Silhouette Score برابر 0.4161 بهترین نتیجه خوشه‌بندی
    را ارائه داد
-   13,885 قانون همبستگی استخراج شد که 431 قانون قوی شناسایی شدند
-   عوامل کلیدی موثر بر عملکرد تحصیلی شامل حضور در کلاس، ساعات مطالعه،
    عملکرد قبلی و حمایت والدین هستند

### ۹.۲ دستاوردهای علمی

این پژوهش نشان داد که:

1.  پیش‌بینی عملکرد تحصیلی یک مسئله پیچیده است که نیازمند رویکردهای
    چندگانه است
2.  ترکیب روش‌های مختلف داده‌کاوی می‌تواند دیدگاه جامع‌تری از عوامل موثر
    ارائه دهد
3.  قوانین همبستگی می‌توانند بینش‌های قابل تفسیری برای مربیان فراهم کنند
4.  خوشه‌بندی می‌تواند در شناسایی گروه‌های همگن دانش‌آموزان برای برنامه‌ریزی
    آموزشی هدفمند مفید باشد

### ۹.۳ کاربردهای عملی

نتایج این پژوهش می‌تواند کاربردهای عملی زیر را داشته باشد:

-   **سیستم هشدار زودهنگام:** شناسایی دانش‌آموزان در معرض خطر در ابتدای
    ترم تحصیلی
-   **برنامه‌ریزی آموزشی شخصی‌سازی شده:** طراحی برنامه‌های حمایتی متناسب با
    نیاز هر گروه
-   **تخصیص بهینه منابع:** اولویت‌بندی تخصیص منابع آموزشی به دانش‌آموزان
    نیازمند
-   **مشاوره تحصیلی هدفمند:** ارائه توصیه‌های مبتنی بر داده به دانش‌آموزان
    و والدین

### ۹.۴ پیشنهادات برای تحقیقات آینده

1.  **جمع‌آوری داده‌های بیشتر:** افزایش حجم نمونه و افزودن ویژگی‌های جدید
    مانند وضعیت اقتصادی-اجتماعی، سلامت روانی، و سبک یادگیری
2.  **استفاده از Deep Learning:** پیاده‌سازی معماری‌های پیشرفته مانند LSTM
    برای تحلیل داده‌های سری زمانی عملکرد تحصیلی
3.  **رویکرد Multi-Task Learning:** پیش‌بینی همزمان چندین جنبه از عملکرد
    تحصیلی
4.  **تحلیل علّی:** استفاده از روش‌های Causal Inference برای شناسایی روابط
    علت و معلولی
5.  **مطالعات طولی:** پیگیری عملکرد دانش‌آموزان در طول زمان برای درک بهتر
    روند تغییرات

::: warning-box
**نکته پایانی:** با وجود عملکرد متوسط مدل‌ها (عملکرد کلی سیستم: 0.4787)،
این پژوهش پایه‌ای مناسب برای توسعه سیستم‌های پیشرفته‌تر پیش‌بینی عملکرد
تحصیلی فراهم می‌کند. بهبود مستمر این سیستم‌ها می‌تواند نقش مهمی در ارتقای
کیفیت آموزش و کاهش نرخ افت تحصیلی داشته باشد.
:::

::: references
## ۱۰. منابع

::: reference-item
\[1\] Romero, C., & Ventura, S. (2020). Educational data mining and
learning analytics: An updated survey. Wiley Interdisciplinary Reviews:
Data Mining and Knowledge Discovery, 10(3), e1355.
:::

::: reference-item
\[2\] Kumar, M., & Pal, R. (2021). Prediction of student\'s performance
using machine learning algorithms. International Journal of Advanced
Computer Science and Applications, 12(7), 243-252.
:::

::: reference-item
\[3\] Breiman, L. (2001). Random forests. Machine learning, 45(1), 5-32.
:::

::: reference-item
\[4\] Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine
learning, 20(3), 273-297.
:::

::: reference-item
\[5\] MacQueen, J. (1967). Some methods for classification and analysis
of multivariate observations. In Proceedings of the fifth Berkeley
symposium on mathematical statistics and probability (Vol. 1, No. 14,
pp. 281-297).
:::

::: reference-item
\[6\] Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996). A
density-based algorithm for discovering clusters in large spatial
databases with noise. In Kdd (Vol. 96, No. 34, pp. 226-231).
:::

::: reference-item
\[7\] McLachlan, G., & Peel, D. (2000). Finite mixture models. John
Wiley & Sons.
:::

::: reference-item
\[8\] Agrawal, R., & Srikant, R. (1994). Fast algorithms for mining
association rules. In Proc. 20th int. conf. very large data bases, VLDB
(Vol. 1215, pp. 487-499).
:::

::: reference-item
\[9\] Han, J., Pei, J., & Yin, Y. (2000). Mining frequent patterns
without candidate generation. ACM sigmod record, 29(2), 1-12.
:::

::: reference-item
\[10\] Friedman, M. (1937). The use of ranks to avoid the assumption of
normality implicit in the analysis of variance. Journal of the american
statistical association, 32(200), 675-701.
:::

::: reference-item
\[11\] Rousseeuw, P. J. (1987). Silhouettes: a graphical aid to the
interpretation and validation of cluster analysis. Journal of
computational and applied mathematics, 20, 53-65.
:::

::: reference-item
\[12\] Davies, D. L., & Bouldin, D. W. (1979). A cluster separation
measure. IEEE transactions on pattern analysis and machine intelligence,
(2), 224-227.
:::

::: reference-item
\[13\] Caliński, T., & Harabasz, J. (1974). A dendrite method for
cluster analysis. Communications in Statistics-theory and Methods, 3(1),
1-27.
:::

::: reference-item
\[14\] Hubert, L., & Arabie, P. (1985). Comparing partitions. Journal of
classification, 2(1), 193-218.
:::

::: reference-item
\[15\] Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion,
B., Grisel, O., \... & Duchesnay, E. (2011). Scikit-learn: Machine
learning in Python. Journal of machine learning research, 12(Oct),
2825-2830.
:::
:::

::: {style="margin-top: 40px; padding-top: 20px; border-top: 2px solid #ddd;"}
## ۱۱. پیوست‌ها

### پیوست الف: نمونه کد پایتون برای پیش‌پردازش داده‌ها

::: {style="background-color: #f5f5f5; padding: 15px; border-radius: 5px; font-family: monospace; font-size: 14px;"}
    # بارگذاری کتابخانه‌ها
    import pandas as pd
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    from sklearn.model_selection import train_test_split

    # بارگذاری داده‌ها
    df = pd.read_csv('student_performance.csv')

    # پردازش مقادیر گمشده
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    for col in numerical_columns:
        df[col].fillna(df[col].mean(), inplace=True)

    # کدگذاری متغیرهای دسته‌ای
    le = LabelEncoder()
    categorical_columns = df.select_dtypes(include=['object']).columns
    for col in categorical_columns:
        df[col + '_Encoded'] = le.fit_transform(df[col])

    # نرمال‌سازی
    scaler = StandardScaler()
    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

    # تقسیم داده‌ها
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
                    
:::

### پیوست ب: جدول معیارهای ارزیابی تفصیلی

  معیار              فرمول                                             محدوده      تفسیر
  ------------------ ------------------------------------------------- ----------- ---------------------------------
  Accuracy           (TP + TN) / (TP + TN + FP + FN)                   \[0, 1\]    نسبت پیش‌بینی‌های صحیح
  Precision          TP / (TP + FP)                                    \[0, 1\]    دقت در پیش‌بینی‌های مثبت
  Recall             TP / (TP + FN)                                    \[0, 1\]    پوشش موارد مثبت واقعی
  F1-Score           2 × (Precision × Recall) / (Precision + Recall)   \[0, 1\]    میانگین هارمونیک دقت و بازخوانی
  Silhouette Score   (b - a) / max(a, b)                               \[-1, 1\]   کیفیت خوشه‌بندی
  Support            freq(X,Y) / N                                     \[0, 1\]    فراوانی نسبی آیتم‌ست
  Confidence         freq(X,Y) / freq(X)                               \[0, 1\]    احتمال شرطی
  Lift               Confidence(X→Y) / Support(Y)                      \[0, ∞)     قدرت قانون

### پیوست ج: لیست فایل‌های خروجی پروژه

-   **processed_student_data.csv:** داده‌های پردازش شده نهایی
-   **train_data.csv:** مجموعه داده آموزشی
-   **test_data.csv:** مجموعه داده تست
-   **best_model.pkl:** بهترین مدل طبقه‌بندی ذخیره شده
-   **clustering_results.pkl:** نتایج کامل خوشه‌بندی
-   **association_rules_all.csv:** تمام قوانین همبستگی استخراج شده
-   **model_comparison_charts.png:** نمودارهای مقایسه مدل‌ها
-   **confusion_matrices_all.png:** ماتریس‌های درهم‌ریختگی
-   **roc_curves.png:** منحنی‌های ROC
-   **elbow_silhouette_analysis.png:** تحلیل Elbow و Silhouette
-   **clustering_visualization.png:** نمایش خوشه‌ها
-   **final_evaluation_report.txt:** گزارش نهایی ارزیابی
:::

::: {style="margin-top: 50px; padding: 20px; background-color: #e3f2fd; border-radius: 10px; text-align: center;"}
### پایان مقاله

این مقاله بر اساس پروژه داده‌کاوی آموزشی با هدف پیش‌بینی عملکرد تحصیلی
دانش‌آموزان تهیه شده است.

**تاریخ تکمیل:** شهریور ۱۴۰۴\
**حجم داده:** ۱۰۰۰ رکورد\
**تعداد ویژگی:** ۱۷ ویژگی\
**روش‌های استفاده شده:** Classification, Clustering, Association Rules
:::
:::
