# ูพุฑูฺู ูพุดโุจู ุนููฺฉุฑุฏ ุฏุงูุดโุขููุฒุงู
# ูุงุฒ 4: ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ (Association Rule Mining)

# ูุงุฑุฏ ฺฉุฑุฏู ฺฉุชุงุจุฎุงููโูุง ููุฑุฏ ูุงุฒ
import pandas as pd
import numpy as np
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import warnings

warnings.filterwarnings('ignore')

# ฺฉุชุงุจุฎุงููโูุง Association Rules
from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules
from mlxtend.preprocessing import TransactionEncoder
import networkx as nx
from itertools import combinations

# ุชูุธูุงุช ููุงุด
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['figure.figsize'] = (12, 8)
sns.set_style("whitegrid")
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)

print("=" * 80)
print("๐ฏ ูุงุฒ 4: ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ (Association Rule Mining)")
print("=" * 80)

# ========================
# 1. ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 1: ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง ูพุฑุฏุงุฒุด ุดุฏู")
print("=" * 60)

# ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง ุจุง ุฎูุดู ุงุฒ ูุงุฒ ูุจู
df = pd.read_csv('data_with_clusters.csv')

# ุจุงุฑฺฏุฐุงุฑ ุฏุงุฏูโูุง ุงุตู ุจุฑุง ุงุทูุงุนุงุช ุจุดุชุฑ
df_original = pd.read_csv('processed_student_data.csv')

print(f"\nโ ุฏุงุฏูโูุง ุจุง ููููุช ุจุงุฑฺฏุฐุงุฑ ุดุฏูุฏ:")
print(f"  โข ุชุนุฏุงุฏ ูููููโูุง: {len(df)}")
print(f"  โข ุชุนุฏุงุฏ ูฺฺฏโูุง: {df.shape[1]}")

# ููุงุด ุณุชููโูุง ููุฌูุฏ
print("\n๐ ุณุชููโูุง ููุฌูุฏ ุฏุฑ ุฏุงุฏูโูุง:")
for i, col in enumerate(df.columns, 1):
    print(f"  {i}. {col}")

# ========================
# 2. ุขูุงุฏูโุณุงุฒ ุฏุงุฏูโูุง ุจุฑุง Association Rules
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 2: ุขูุงุฏูโุณุงุฒ ุฏุงุฏูโูุง ุจุฑุง Association Rules")
print("=" * 60)

# ุงุฌุงุฏ ฺฉ ฺฉูพ ุงุฒ ุฏุงุฏูโูุง ุจุฑุง ูพุฑุฏุงุฒุด
df_rules = df.copy()

# ุชุจุฏู ูฺฺฏโูุง ูพูุณุชู ุจู ุฏุณุชูโุง
print("\n๐ ุชุจุฏู ูฺฺฏโูุง ูพูุณุชู ุจู ุฏุณุชูโุง...")

# 2.1. AttendanceRate - ูุฑุฎ ุญุถูุฑ
if 'AttendanceRate' in df_rules.columns:
    df_rules['Attendance_Level'] = pd.cut(df_rules['AttendanceRate'],
                                          bins=[-np.inf, -0.5, 0.5, np.inf],
                                          labels=['Low_Attendance', 'Medium_Attendance', 'High_Attendance'])

# 2.2. StudyHoursPerWeek - ุณุงุนุงุช ูุทุงูุนู
if 'StudyHoursPerWeek' in df_rules.columns:
    df_rules['Study_Level'] = pd.cut(df_rules['StudyHoursPerWeek'],
                                     bins=[-np.inf, -0.5, 0.5, np.inf],
                                     labels=['Low_Study', 'Medium_Study', 'High_Study'])

# 2.3. PreviousGrade - ููุฑู ูุจู
if 'PreviousGrade' in df_rules.columns:
    df_rules['Previous_Performance'] = pd.cut(df_rules['PreviousGrade'],
                                              bins=[-np.inf, -0.5, 0.5, np.inf],
                                              labels=['Poor_Previous', 'Average_Previous', 'Good_Previous'])

# 2.4. ExtracurricularActivities - ูุนุงูุชโูุง ููู ุจุฑูุงูู
if 'ExtracurricularActivities' in df_rules.columns:
    df_rules['Activities_Level'] = pd.cut(df_rules['ExtracurricularActivities'],
                                          bins=[-np.inf, -0.5, 0.5, np.inf],
                                          labels=['Low_Activities', 'Medium_Activities', 'High_Activities'])

# 2.5. Gender
if 'Gender_Encoded' in df_rules.columns:
    df_rules['Gender_Category'] = df_rules['Gender_Encoded'].apply(
        lambda x: 'Male' if x == 1 else 'Female'
    )

# 2.6. ParentalSupport
if 'ParentalSupport_Encoded' in df_rules.columns:
    df_rules['Parental_Category'] = df_rules['ParentalSupport_Encoded'].apply(
        lambda x: 'High_Support' if x == 0 else 'Medium_Support' if x == 2 else 'Low_Support'
    )

# 2.7. Pass Status - ูุถุนุช ูุจูู
if 'Pass_Status_Encoded' in df_rules.columns:
    df_rules['Pass_Result'] = df_rules['Pass_Status_Encoded'].apply(
        lambda x: 'Pass' if x == 1 else 'Fail'
    )

# 2.8. Cluster
if 'Cluster' in df_rules.columns:
    df_rules['Cluster_Group'] = df_rules['Cluster'].apply(
        lambda x: f'Cluster_{x + 1}'
    )

# ุงูุชุฎุงุจ ุณุชููโูุง ุฏุณุชูโุง ุจุฑุง ุชุญูู
categorical_columns = ['Attendance_Level', 'Study_Level', 'Previous_Performance',
                       'Activities_Level', 'Gender_Category', 'Parental_Category',
                       'Pass_Result', 'Cluster_Group']

# ููุชุฑ ฺฉุฑุฏู ุณุชููโูุง ููุฌูุฏ
available_columns = [col for col in categorical_columns if col in df_rules.columns]

print(f"\nโ {len(available_columns)} ูฺฺฏ ุฏุณุชูโุง ุขูุงุฏู ุดุฏูุฏ:")
for col in available_columns:
    print(f"  โข {col}")

# ========================
# 3. ุชุจุฏู ุจู ูุฑูุช Transaction
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 3: ุชุจุฏู ุฏุงุฏูโูุง ุจู ูุฑูุช Transaction")
print("=" * 60)

# ุงุฌุงุฏ transaction ุจุฑุง ูุฑ ุฑฺฉูุฑุฏ
transactions = []
for idx, row in df_rules[available_columns].iterrows():
    transaction = []
    for col in available_columns:
        if pd.notna(row[col]):
            transaction.append(f"{col}={row[col]}")
    transactions.append(transaction)

print(f"\nโ {len(transactions)} ุชุฑุงฺฉูุด ุงุฌุงุฏ ุดุฏ")
print("\n๐ ูููููโุง ุงุฒ ุชุฑุงฺฉูุดโูุง:")
for i in range(min(3, len(transactions))):
    print(f"  ุชุฑุงฺฉูุด {i + 1}: {transactions[i][:4]}...")

# ุชุจุฏู ุจู ูุฑูุช One-Hot Encoding
te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
df_encoded = pd.DataFrame(te_ary, columns=te.columns_)

print(f"\nโ ูุงุชุฑุณ One-Hot Encoding ุงุฌุงุฏ ุดุฏ:")
print(f"  โข ุงุจุนุงุฏ: {df_encoded.shape}")
print(f"  โข ุชุนุฏุงุฏ ุขุชูโูุง ฺฉุชุง: {len(df_encoded.columns)}")

# ========================
# 4. ุงุฌุฑุง ุงูฺฏูุฑุชู Apriori
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 4: ุงุฌุฑุง ุงูฺฏูุฑุชู Apriori")
print("=" * 60)

# ุชูุธู ูพุงุฑุงูุชุฑูุง Apriori
min_support = 0.01  # ุญุฏุงูู ูพุดุชุจุงู
min_confidence = 0.5  # ุญุฏุงูู ุงุทููุงู

print(f"\nโ๏ธ ูพุงุฑุงูุชุฑูุง Apriori:")
print(f"  โข ุญุฏุงูู Support: {min_support}")
print(f"  โข ุญุฏุงูู Confidence: {min_confidence}")

# ุงุฌุฑุง Apriori
print("\n๐ ุฏุฑ ุญุงู ุงุฌุฑุง ุงูฺฏูุฑุชู Apriori...")
frequent_itemsets_apriori = apriori(df_encoded, min_support=min_support, use_colnames=True)

print(f"\nโ ุชุนุฏุงุฏ ูุฌููุนูโูุง ูพุฑุชฺฉุฑุงุฑ ุงูุช ุดุฏู: {len(frequent_itemsets_apriori)}")

# ููุงุด top frequent itemsets
if len(frequent_itemsets_apriori) > 0:
    print("\n๐ 10 ูุฌููุนู ูพุฑุชฺฉุฑุงุฑ ุจุฑุชุฑ:")
    top_itemsets = frequent_itemsets_apriori.nlargest(10, 'support')
    for idx, row in top_itemsets.iterrows():
        itemset = list(row['itemsets'])
        support = row['support']
        print(f"  โข {itemset} -> Support: {support:.4f}")

# ========================
# 5. ุงุฌุฑุง ุงูฺฏูุฑุชู FP-Growth
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 5: ุงุฌุฑุง ุงูฺฏูุฑุชู FP-Growth")
print("=" * 60)

print("\n๐ ุฏุฑ ุญุงู ุงุฌุฑุง ุงูฺฏูุฑุชู FP-Growth...")
frequent_itemsets_fp = fpgrowth(df_encoded, min_support=min_support, use_colnames=True)

print(f"\nโ ุชุนุฏุงุฏ ูุฌููุนูโูุง ูพุฑุชฺฉุฑุงุฑ ุงูุช ุดุฏู: {len(frequent_itemsets_fp)}")

# ููุงุณู ุจุง Apriori
print(f"\n๐ ููุงุณู ุงูฺฏูุฑุชูโูุง:")
print(f"  โข Apriori: {len(frequent_itemsets_apriori)} itemset")
print(f"  โข FP-Growth: {len(frequent_itemsets_fp)} itemset")

# ุงุณุชูุงุฏู ุงุฒ FP-Growth ุจุฑุง ุงุฏุงูู (ูุนูููุงู ุณุฑุนโุชุฑ ุงุณุช)
frequent_itemsets = frequent_itemsets_fp

# ========================
# 6. ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 6: ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ")
print("=" * 60)

if len(frequent_itemsets) > 0:
    # ุงุณุชุฎุฑุงุฌ ููุงูู
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)

    # ูุญุงุณุจู ูุนุงุฑูุง ุงุถุงู
    rules['conviction'] = np.where(rules['confidence'] == 1, np.inf,
                                   (1 - rules['consequent support']) / (1 - rules['confidence']))

    print(f"\nโ ุชุนุฏุงุฏ ููุงูู ุงุณุชุฎุฑุงุฌ ุดุฏู: {len(rules)}")

    if len(rules) > 0:
        # ูุฑุชุจโุณุงุฒ ุจุฑ ุงุณุงุณ Lift
        rules_sorted = rules.sort_values('lift', ascending=False)

        print("\n๐ ุขูุงุฑ ฺฉู ููุงูู:")
        print(f"  โข ูุงูฺฏู Support: {rules['support'].mean():.4f}")
        print(f"  โข ูุงูฺฏู Confidence: {rules['confidence'].mean():.4f}")
        print(f"  โข ูุงูฺฏู Lift: {rules['lift'].mean():.4f}")
        print(f"  โข ุญุฏุงฺฉุซุฑ Lift: {rules['lift'].max():.4f}")

        # ุฐุฎุฑู ููุงูู
        rules_sorted.to_csv('association_rules_all.csv', index=False, encoding='utf-8-sig')
        print("\nโ ุชูุงู ููุงูู ุฏุฑ 'association_rules_all.csv' ุฐุฎุฑู ุดุฏูุฏ.")
    else:
        print("\nโ๏ธ ูฺ ูุงููู ุจุง ูพุงุฑุงูุชุฑูุง ุฏุงุฏู ุดุฏู ุงูุช ูุดุฏ.")
        rules_sorted = pd.DataFrame()
else:
    print("\nโ๏ธ ูุฌููุนูโูุง ูพุฑุชฺฉุฑุงุฑ ฺฉุงู ุงูุช ูุดุฏ.")
    rules_sorted = pd.DataFrame()

# ========================
# 7. ุชุญูู ููุงูู ูุฑุชุจุท ุจุง ูุจูู/ุฑุฏ
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 7: ุชุญูู ููุงูู ูุฑุชุจุท ุจุง ุนููฺฉุฑุฏ ุชุญุตู")
print("=" * 60)

if len(rules_sorted) > 0:
    # ููุงูู ููุชู ุจู ูุจูู
    pass_rules = rules_sorted[rules_sorted['consequents'].apply(lambda x: 'Pass_Result=Pass' in str(x))]

    # ููุงูู ููุชู ุจู ุฑุฏ
    fail_rules = rules_sorted[rules_sorted['consequents'].apply(lambda x: 'Pass_Result=Fail' in str(x))]

    print(f"\n๐ ููุงูู ูุฑุชุจุท ุจุง ูุชุฌู ุชุญุตู:")
    print(f"  โข ููุงูู ููุชู ุจู ูุจูู: {len(pass_rules)}")
    print(f"  โข ููุงูู ููุชู ุจู ุฑุฏ: {len(fail_rules)}")

    # ููุงุด ุจูุชุฑู ููุงูู ุจุฑุง ูุจูู
    if len(pass_rules) > 0:
        print("\nโ 5 ูุงููู ุจุฑุชุฑ ููุชู ุจู ูุจูู (ุจุฑ ุงุณุงุณ Lift):")
        print("โ" * 70)
        for idx, rule in pass_rules.head(5).iterrows():
            antecedents = ', '.join(list(rule['antecedents']))
            consequents = ', '.join(list(rule['consequents']))
            print(f"\n๐ ูุงููู {idx + 1}:")
            print(f"  ุงฺฏุฑ: {antecedents}")
            print(f"  ุขูฺฏุงู: {consequents}")
            print(f"  โข Support: {rule['support']:.4f}")
            print(f"  โข Confidence: {rule['confidence']:.4f}")
            print(f"  โข Lift: {rule['lift']:.4f}")

        # ุฐุฎุฑู ููุงูู ูุจูู
        pass_rules.to_csv('rules_for_pass.csv', index=False, encoding='utf-8-sig')
        print("\nโ ููุงูู ูุจูู ุฏุฑ 'rules_for_pass.csv' ุฐุฎุฑู ุดุฏูุฏ.")

    # ููุงุด ุจูุชุฑู ููุงูู ุจุฑุง ุฑุฏ
    if len(fail_rules) > 0:
        print("\nโ 5 ูุงููู ุจุฑุชุฑ ููุชู ุจู ุฑุฏ (ุจุฑ ุงุณุงุณ Lift):")
        print("โ" * 70)
        for idx, rule in fail_rules.head(5).iterrows():
            antecedents = ', '.join(list(rule['antecedents']))
            consequents = ', '.join(list(rule['consequents']))
            print(f"\n๐ ูุงููู {idx + 1}:")
            print(f"  ุงฺฏุฑ: {antecedents}")
            print(f"  ุขูฺฏุงู: {consequents}")
            print(f"  โข Support: {rule['support']:.4f}")
            print(f"  โข Confidence: {rule['confidence']:.4f}")
            print(f"  โข Lift: {rule['lift']:.4f}")

        # ุฐุฎุฑู ููุงูู ุฑุฏ
        fail_rules.to_csv('rules_for_fail.csv', index=False, encoding='utf-8-sig')
        print("\nโ ููุงูู ุฑุฏ ุฏุฑ 'rules_for_fail.csv' ุฐุฎุฑู ุดุฏูุฏ.")

# ========================
# 8. ุชุญูู ููุงูู ูู
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 8: ุดูุงุณุง ููุงูู ูู ู ูุนูุงุฏุงุฑ")
print("=" * 60)

if len(rules_sorted) > 0:
    # ููุชุฑ ููุงูู ูู
    strong_rules = rules_sorted[(rules_sorted['confidence'] >= 0.7) &
                                (rules_sorted['lift'] > 1.2) &
                                (rules_sorted['support'] >= 0.05)]

    print(f"\n๐ ุชุนุฏุงุฏ ููุงูู ูู: {len(strong_rules)}")
    print("  ูุนุงุฑูุง: Confidence >= 0.7, Lift > 1.2, Support >= 0.05")

    if len(strong_rules) > 0:
        print("\n๐ 10 ูุงููู ูู ุจุฑุชุฑ:")
        print("โ" * 70)
        for idx, rule in strong_rules.head(10).iterrows():
            antecedents = ', '.join(list(rule['antecedents']))
            consequents = ', '.join(list(rule['consequents']))
            print(f"\n๐ ูุงููู:")
            print(f"  {antecedents} โ {consequents}")
            print(f"  [Sup:{rule['support']:.3f}, Conf:{rule['confidence']:.3f}, Lift:{rule['lift']:.3f}]")

        # ุฐุฎุฑู ููุงูู ูู
        strong_rules.to_csv('strong_rules.csv', index=False, encoding='utf-8-sig')
        print("\nโ ููุงูู ูู ุฏุฑ 'strong_rules.csv' ุฐุฎุฑู ุดุฏูุฏ.")

# ========================
# 9. Visualization ููุงูู
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 9: ุฑุณู ูููุฏุงุฑูุง ุชุญูู")
print("=" * 60)

if len(rules_sorted) > 0:
    # 9.1. ูููุฏุงุฑ ูพุฑุงฺฉูุฏฺฏ Support vs Confidence
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))

    # Plot 1: Support vs Confidence
    scatter1 = axes[0, 0].scatter(rules_sorted['support'], rules_sorted['confidence'],
                                  c=rules_sorted['lift'], cmap='viridis',
                                  alpha=0.6, s=50)
    axes[0, 0].set_xlabel('Support')
    axes[0, 0].set_ylabel('Confidence')
    axes[0, 0].set_title('Support vs Confidence (colored by Lift)')
    plt.colorbar(scatter1, ax=axes[0, 0])

    # Plot 2: Support vs Lift
    axes[0, 1].scatter(rules_sorted['support'], rules_sorted['lift'],
                       alpha=0.6, s=50, color='coral')
    axes[0, 1].set_xlabel('Support')
    axes[0, 1].set_ylabel('Lift')
    axes[0, 1].set_title('Support vs Lift')
    axes[0, 1].axhline(y=1, color='r', linestyle='--', alpha=0.5)

    # Plot 3: Confidence vs Lift
    axes[1, 0].scatter(rules_sorted['confidence'], rules_sorted['lift'],
                       alpha=0.6, s=50, color='green')
    axes[1, 0].set_xlabel('Confidence')
    axes[1, 0].set_ylabel('Lift')
    axes[1, 0].set_title('Confidence vs Lift')
    axes[1, 0].axhline(y=1, color='r', linestyle='--', alpha=0.5)

    # Plot 4: Distribution of Lift
    axes[1, 1].hist(rules_sorted['lift'], bins=30, color='skyblue', edgecolor='black')
    axes[1, 1].set_xlabel('Lift')
    axes[1, 1].set_ylabel('Frequency')
    axes[1, 1].set_title('Distribution of Lift Values')
    axes[1, 1].axvline(x=1, color='r', linestyle='--', alpha=0.5)

    plt.suptitle('Association Rules Analysis', fontsize=16)
    plt.tight_layout()
    plt.savefig('association_rules_analysis.png', dpi=100, bbox_inches='tight')
    print("โ ูููุฏุงุฑ ุชุญูู ููุงูู ุฏุฑ 'association_rules_analysis.png' ุฐุฎุฑู ุดุฏ.")
    plt.close()

    # 9.2. ูููุฏุงุฑ Heat Map ุจุฑุง Support-Confidence
    if len(rules_sorted) > 20:
        top_rules = rules_sorted.head(20)
    else:
        top_rules = rules_sorted

    plt.figure(figsize=(12, 8))
    metrics_df = top_rules[['support', 'confidence', 'lift']].T
    metrics_df.columns = [f"Rule {i + 1}" for i in range(len(metrics_df.columns))]

    sns.heatmap(metrics_df, annot=True, fmt='.3f', cmap='YlOrRd', cbar=True)
    plt.title('Top Association Rules Metrics Heatmap')
    plt.ylabel('Metrics')
    plt.xlabel('Rules')
    plt.tight_layout()
    plt.savefig('rules_heatmap.png', dpi=100, bbox_inches='tight')
    print("โ Heat Map ููุงูู ุฏุฑ 'rules_heatmap.png' ุฐุฎุฑู ุดุฏ.")
    plt.close()

# ========================
# 10. Network Graph ููุงูู
# ========================
print("\n๐ ุงุฌุงุฏ ฺฏุฑุงู ุดุจฺฉูโุง ููุงูู...")

if len(rules_sorted) > 0 and len(rules_sorted) <= 100:  # ููุท ุจุฑุง ุชุนุฏุงุฏ ูุญุฏูุฏ ููุงูู
    # ุงูุชุฎุงุจ ููุงูู ุจุฑุชุฑ ุจุฑุง ููุงุด
    if len(rules_sorted) > 30:
        network_rules = rules_sorted.head(30)
    else:
        network_rules = rules_sorted

    # ุงุฌุงุฏ ฺฏุฑุงู
    G = nx.DiGraph()

    # ุงุถุงูู ฺฉุฑุฏู ุงูโูุง
    for idx, rule in network_rules.iterrows():
        for antecedent in rule['antecedents']:
            for consequent in rule['consequents']:
                G.add_edge(antecedent, consequent,
                           weight=rule['lift'],
                           support=rule['support'],
                           confidence=rule['confidence'])

    # ุฑุณู ฺฏุฑุงู
    plt.figure(figsize=(15, 10))
    pos = nx.spring_layout(G, k=2, iterations=50)

    # ุฑุณู ฺฏุฑูโูุง
    node_colors = ['lightblue' if 'Pass' in node else 'lightcoral' if 'Fail' in node else 'lightgreen'
                   for node in G.nodes()]
    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=1000, alpha=0.8)

    # ุฑุณู ุงูโูุง
    edges = G.edges()
    weights = [G[u][v]['weight'] for u, v in edges]
    nx.draw_networkx_edges(G, pos, width=weights, alpha=0.5, arrows=True, arrowsize=20)

    # ุงุถุงูู ฺฉุฑุฏู ุจุฑฺุณุจโูุง
    nx.draw_networkx_labels(G, pos, font_size=8, font_weight='bold')

    plt.title('Association Rules Network Graph', fontsize=16)
    plt.axis('off')
    plt.tight_layout()
    plt.savefig('rules_network_graph.png', dpi=100, bbox_inches='tight')
    print("โ ฺฏุฑุงู ุดุจฺฉู ููุงูู ุฏุฑ 'rules_network_graph.png' ุฐุฎุฑู ุดุฏ.")
    plt.close()

# ========================
# 11. ุชุญูู ุงูฺฏููุง ฺฉูุฏ
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 10: ุงุณุชุฎุฑุงุฌ ุงูฺฏููุง ฺฉูุฏ ู ุชูุตูโูุง")
print("=" * 60)

print("\n๐ ุงูฺฏููุง ฺฉุดู ุดุฏู:")
print("โ" * 50)

# ุชุญูู ุนูุงูู ููุซุฑ ุจุฑ ูุจูู
if len(rules_sorted) > 0:
    # ุดูุงุณุง ุนูุงูู ูุซุจุช (ููุฌุฑ ุจู ูุจูู)
    positive_factors = set()
    if 'Pass_Result=Pass' in str(rules_sorted['consequents'].values):
        pass_antecedents = pass_rules['antecedents'].apply(lambda x: list(x))
        for ant_list in pass_antecedents:
            positive_factors.update(ant_list)

    # ุดูุงุณุง ุนูุงูู ููู (ููุฌุฑ ุจู ุฑุฏ)
    negative_factors = set()
    if 'Pass_Result=Fail' in str(rules_sorted['consequents'].values):
        fail_antecedents = fail_rules['antecedents'].apply(lambda x: list(x))
        for ant_list in fail_antecedents:
            negative_factors.update(ant_list)

    print("\nโ ุนูุงูู ูุซุจุช (ูุฑุชุจุท ุจุง ูุจูู):")
    for factor in list(positive_factors)[:10]:
        if 'High' in factor or 'Good' in factor:
            print(f"  โข {factor}")

    print("\nโ ุนูุงูู ููู (ูุฑุชุจุท ุจุง ุฑุฏ):")
    for factor in list(negative_factors)[:10]:
        if 'Low' in factor or 'Poor' in factor:
            print(f"  โข {factor}")

# ========================
# 12. ุชูุตูโูุง ุขููุฒุด
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 11: ุชูุตูโูุง ุขููุฒุด ุจุฑ ุงุณุงุณ ููุงูู")
print("=" * 60)

print("\n๐ก ุชูุตูโูุง ุขููุฒุด ุจุฑ ุงุณุงุณ ููุงูู ฺฉุดู ุดุฏู:")
print("โ" * 50)

recommendations = []

# ุชุญูู ููุงูู ู ุงุฑุงุฆู ุชูุตู
if len(rules_sorted) > 0:
    # ุชูุตู 1: ุญุถูุฑ ุฏุฑ ฺฉูุงุณ
    attendance_rules = rules_sorted[rules_sorted['antecedents'].apply(
        lambda x: any('Attendance' in str(item) for item in x))]
    if len(attendance_rules) > 0:
        high_attendance_pass = attendance_rules[
            (attendance_rules['antecedents'].apply(lambda x: 'High_Attendance' in str(x))) &
            (attendance_rules['consequents'].apply(lambda x: 'Pass' in str(x)))
            ]
        if len(high_attendance_pass) > 0:
            avg_conf = high_attendance_pass['confidence'].mean()
            recommendations.append(f"ุญุถูุฑ ููุธู ุฏุฑ ฺฉูุงุณ (Confidence: {avg_conf:.2%})")

    # ุชูุตู 2: ุณุงุนุงุช ูุทุงูุนู
    study_rules = rules_sorted[rules_sorted['antecedents'].apply(
        lambda x: any('Study' in str(item) for item in x))]
    if len(study_rules) > 0:
        high_study_pass = study_rules[
            (study_rules['antecedents'].apply(lambda x: 'High_Study' in str(x))) &
            (study_rules['consequents'].apply(lambda x: 'Pass' in str(x)))
            ]
        if len(high_study_pass) > 0:
            avg_conf = high_study_pass['confidence'].mean()
            recommendations.append(f"ุงูุฒุงุด ุณุงุนุงุช ูุทุงูุนู (Confidence: {avg_conf:.2%})")

    # ุชูุตู 3: ุญูุงุช ูุงูุฏู
    parental_rules = rules_sorted[rules_sorted['antecedents'].apply(
        lambda x: any('Parental' in str(item) for item in x))]
    if len(parental_rules) > 0:
        high_support_pass = parental_rules[
            (parental_rules['antecedents'].apply(lambda x: 'High_Support' in str(x))) &
            (parental_rules['consequents'].apply(lambda x: 'Pass' in str(x)))
            ]
        if len(high_support_pass) > 0:
            avg_conf = high_support_pass['confidence'].mean()
            recommendations.append(f"ุชููุช ุญูุงุช ุฎุงููุงุฏู (Confidence: {avg_conf:.2%})")

print("\n๐ ุชูุตูโูุง ฺฉูุฏ ุจุฑุง ุจูุจูุฏ ุนููฺฉุฑุฏ:")
if recommendations:
    for i, rec in enumerate(recommendations, 1):
        print(f"  {i}. {rec}")
else:
    print("  โข ุชููุช ุญุถูุฑ ููุธู ุฏุฑ ฺฉูุงุณ")
    print("  โข ุงูุฒุงุด ุณุงุนุงุช ูุทุงูุนู ููุชฺฏ")
    print("  โข ูุดุงุฑฺฉุช ุฏุฑ ูุนุงูุชโูุง ููู ุจุฑูุงูู")
    print("  โข ุฌูุจ ุญูุงุช ุจุดุชุฑ ุฎุงููุงุฏู")

# ========================
# 13. ุฐุฎุฑู ูุชุงุฌ ููุง
# ========================
print("\n" + "=" * 60)
print("ูุฑุญูู 12: ุฐุฎุฑู ูุชุงุฌ ุชุญูู")
print("=" * 60)

# ุงุฌุงุฏ ุฏฺฉุดูุฑ ูุชุงุฌ
results_summary = {
    'total_transactions': len(transactions),
    'unique_items': len(df_encoded.columns),
    'frequent_itemsets_count': len(frequent_itemsets) if 'frequent_itemsets' in locals() else 0,
    'total_rules': len(rules_sorted) if 'rules_sorted' in locals() else 0,
    'pass_rules_count': len(pass_rules) if 'pass_rules' in locals() else 0,
    'fail_rules_count': len(fail_rules) if 'fail_rules' in locals() else 0,
    'strong_rules_count': len(strong_rules) if 'strong_rules' in locals() else 0,
    'min_support': min_support,
    'min_confidence': min_confidence
}

# ุฐุฎุฑู ุฎูุงุตู ูุชุงุฌ
with open('association_rules_summary.pkl', 'wb') as f:
    pickle.dump(results_summary, f)

print("โ ุฎูุงุตู ูุชุงุฌ ุฏุฑ 'association_rules_summary.pkl' ุฐุฎุฑู ุดุฏ.")

# ุงุฌุงุฏ ฺฏุฒุงุฑุด ููุง
report = []
report.append("=" * 70)
report.append("ฺฏุฒุงุฑุด ููุง - ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ")
report.append("=" * 70)
report.append(f"\n๐ ุขูุงุฑ ฺฉู:")
report.append(f"  โข ุชุนุฏุงุฏ ุชุฑุงฺฉูุดโูุง: {results_summary['total_transactions']}")
report.append(f"  โข ุชุนุฏุงุฏ ุขุชูโูุง ฺฉุชุง: {results_summary['unique_items']}")
report.append(f"  โข ูุฌููุนูโูุง ูพุฑุชฺฉุฑุงุฑ: {results_summary['frequent_itemsets_count']}")
report.append(f"  โข ฺฉู ููุงูู ุงุณุชุฎุฑุงุฌ ุดุฏู: {results_summary['total_rules']}")
report.append(f"  โข ููุงูู ููุชู ุจู ูุจูู: {results_summary['pass_rules_count']}")
report.append(f"  โข ููุงูู ููุชู ุจู ุฑุฏ: {results_summary['fail_rules_count']}")
report.append(f"  โข ููุงูู ูู: {results_summary['strong_rules_count']}")

if len(rules_sorted) > 0:
    report.append(f"\n๐ ูุนุงุฑูุง ุนููฺฉุฑุฏ:")
    report.append(f"  โข ูุงูฺฏู Support: {rules_sorted['support'].mean():.4f}")
    report.append(f"  โข ูุงูฺฏู Confidence: {rules_sorted['confidence'].mean():.4f}")
    report.append(f"  โข ูุงูฺฏู Lift: {rules_sorted['lift'].mean():.4f}")
    report.append(f"  โข ุจุดุชุฑู Lift: {rules_sorted['lift'].max():.4f}")

report.append("\n๐ก ุจูุดโูุง ฺฉูุฏ:")
if len(pass_rules) > 0 and len(fail_rules) > 0:
    # ุจูุด 1
    if len(pass_rules) > len(fail_rules):
        report.append("  โข ููุงูู ููุชู ุจู ูุจูู ุจุดุชุฑ ุงุฒ ููุงูู ููุชู ุจู ุฑุฏ ูุณุชูุฏ")
    else:
        report.append("  โข ููุงูู ููุชู ุจู ุฑุฏ ุจุดุชุฑ ุงุฒ ููุงูู ููุชู ุจู ูุจูู ูุณุชูุฏ")

    # ุจูุด 2
    if 'High_Study' in str(pass_rules['antecedents'].values):
        report.append("  โข ุณุงุนุงุช ูุทุงูุนู ุจุงูุง ุงุฑุชุจุงุท ูุซุจุช ุจุง ูุจูู ุฏุงุฑุฏ")

    # ุจูุด 3
    if 'High_Attendance' in str(pass_rules['antecedents'].values):
        report.append("  โข ุญุถูุฑ ููุธู ุฏุฑ ฺฉูุงุณ ุนุงูู ููู ุฏุฑ ููููุช ุชุญุตู ุงุณุช")

# ุฐุฎุฑู ฺฏุฒุงุฑุด
with open('association_rules_report.txt', 'w', encoding='utf-8') as f:
    f.write('\n'.join(report))

print("โ ฺฏุฒุงุฑุด ููุง ุฏุฑ 'association_rules_report.txt' ุฐุฎุฑู ุดุฏ.")

# ========================
# 14. ฺฏุฒุงุฑุด ููุง
# ========================
print("\n" + "=" * 80)
print("โ ูุงุฒ 4: ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ ุจุง ููููุช ุชฺฉูู ุดุฏ!")
print("=" * 80)

print("\n๐ ุฎูุงุตู ุนููุงุช ุงูุฌุงู ุดุฏู:")
print("โ" * 40)
print("1. โ ุจุงุฑฺฏุฐุงุฑ ู ุขูุงุฏูโุณุงุฒ ุฏุงุฏูโูุง")
print("2. โ ุชุจุฏู ูฺฺฏโูุง ูพูุณุชู ุจู ุฏุณุชูโุง")
print("3. โ ุงุฌุงุฏ ูุฑูุช Transaction")
print("4. โ ุงุฌุฑุง ุงูฺฏูุฑุชู Apriori")
print("5. โ ุงุฌุฑุง ุงูฺฏูุฑุชู FP-Growth")
print("6. โ ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ")
print("7. โ ุชุญูู ููุงูู ูุฑุชุจุท ุจุง ูุจูู/ุฑุฏ")
print("8. โ ุดูุงุณุง ููุงูู ูู ู ูุนูุงุฏุงุฑ")
print("9. โ ุงุฌุงุฏ ูููุฏุงุฑูุง ุชุญูู")
print("10. โ ุงุณุชุฎุฑุงุฌ ุงูฺฏููุง ฺฉูุฏ")
print("11. โ ุงุฑุงุฆู ุชูุตูโูุง ุขููุฒุด")

print("\n๐ ูุงูโูุง ุชููุฏ ุดุฏู:")
print("โ" * 40)
print("  โข association_rules_all.csv - ุชูุงู ููุงูู ุงุณุชุฎุฑุงุฌ ุดุฏู")
print("  โข rules_for_pass.csv - ููุงูู ููุชู ุจู ูุจูู")
print("  โข rules_for_fail.csv - ููุงูู ููุชู ุจู ุฑุฏ")
print("  โข strong_rules.csv - ููุงูู ูู ู ูุนูุงุฏุงุฑ")
print("  โข association_rules_analysis.png - ูููุฏุงุฑูุง ุชุญูู")
print("  โข rules_heatmap.png - Heat Map ูุนุงุฑูุง ููุงูู")
print("  โข rules_network_graph.png - ฺฏุฑุงู ุดุจฺฉู ููุงูู")
print("  โข association_rules_summary.pkl - ุฎูุงุตู ูุชุงุฌ")
print("  โข association_rules_report.txt - ฺฏุฒุงุฑุด ููุง")

print("\n๐ ูุชุงุฌ ฺฉูุฏ:")
print("โ" * 40)
print(f"  โข ุชุนุฏุงุฏ ฺฉู ููุงูู: {results_summary['total_rules']}")
print(f"  โข ููุงูู ูู: {results_summary['strong_rules_count']}")
print(f"  โข ูุฌููุนูโูุง ูพุฑุชฺฉุฑุงุฑ: {results_summary['frequent_itemsets_count']}")

if len(rules_sorted) > 0:
    # ููุงุด ููโุชุฑู ูุงููู
    strongest_rule = rules_sorted.iloc[0]
    print(f"\n๐ ููโุชุฑู ูุงููู (ุจุฑ ุงุณุงุณ Lift):")
    print(f"  {list(strongest_rule['antecedents'])} โ {list(strongest_rule['consequents'])}")
    print(f"  Lift: {strongest_rule['lift']:.3f}, Confidence: {strongest_rule['confidence']:.3f}")

print("\n๐ก ูุชุฌูโฺฏุฑ ููุง:")
print("โ" * 40)
print("ุจุฑ ุงุณุงุณ ุชุญูู ููุงูู ููุจุณุชฺฏุ ุนูุงูู ฺฉูุฏ ููุซุฑ ุจุฑ ููููุช ุชุญุตู ุดูุงุณุง ุดุฏูุฏ.")
print("ุงู ููุงูู ูโุชูุงููุฏ ุจุฑุง:")
print("  โข ูพุดโุจู ุนููฺฉุฑุฏ ุฏุงูุดโุขููุฒุงู")
print("  โข ุดูุงุณุง ุฏุงูุดโุขููุฒุงู ุฏุฑ ูุนุฑุถ ุฎุทุฑ")
print("  โข ุทุฑุงุญ ุจุฑูุงููโูุง ุญูุงุช ูุฏูููุฏ")
print("  โข ุจูุจูุฏ ุงุณุชุฑุงุชฺโูุง ุขููุฒุด")
print("ููุฑุฏ ุงุณุชูุงุฏู ูุฑุงุฑ ฺฏุฑูุฏ.")

print("\n" + "=" * 80)
print("๐ ูพุฑูฺู ูพุดโุจู ุนููฺฉุฑุฏ ุฏุงูุดโุขููุฒุงู - ุชฺฉูู ุดุฏ!")
print("=" * 80)
print("\n๐ ุชูุงู 4 ูุงุฒ ูพุฑูฺู ุจุง ููููุช ุงูุฌุงู ุดุฏ:")
print("  โ ูุงุฒ 1: ูพุดโูพุฑุฏุงุฒุด ุฏุงุฏูโูุง")
print("  โ ูุงุฒ 2: ูุฏูโูุง ุทุจููโุจูุฏ")
print("  โ ูุงุฒ 3: ุฎูุดูโุจูุฏ ุฏุงูุดโุขููุฒุงู")
print("  โ ูุงุฒ 4: ุงุณุชุฎุฑุงุฌ ููุงูู ููุจุณุชฺฏ")
print("\n" + "=" * 80)